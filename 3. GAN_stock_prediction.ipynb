{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 262 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.006397</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.269540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.005530</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.277210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003480</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>0.386136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006016</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>0.010104</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.132201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close    Volume  Dividends  Stock Splits\n",
       "0  0.002198  0.000487  0.006397  0.001871  0.000000        0.4           0.0\n",
       "1  0.001843  0.000000  0.003596  0.001100  0.269540        0.0           0.0\n",
       "2  0.000939  0.002022  0.005530  0.003165  0.277210        0.0           0.0\n",
       "3  0.003480  0.003948  0.008077  0.005852  0.386136        0.0           0.0\n",
       "4  0.006016  0.004188  0.010104  0.005416  0.132201        0.0           0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data = pd.read_csv(\"normalized_stock_data.csv\")\n",
    "\n",
    "print(f\"there are {len(normalized_data)} rows\")\n",
    "normalized_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232\n"
     ]
    }
   ],
   "source": [
    "# create segmented sequences\n",
    "def create_sequence(data, seq_len):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - seq_len):\n",
    "        sequences.append(data[i : i + seq_len])\n",
    "    return np.array(sequences)\n",
    "\n",
    "sequence_length = 30\n",
    "sequences = create_sequence(normalized_data, sequence_length)\n",
    "# [[row1, row2, row3], .... []]\n",
    "\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 162\n",
      "test size: 70\n",
      "train sequences: 162\n",
      "test sequences: 70\n"
     ]
    }
   ],
   "source": [
    "# train-test split (70-30 split)\n",
    "split_ratio = 0.7\n",
    "train_size = int(len(sequences) * split_ratio)\n",
    "\n",
    "print(f\"train size: {train_size}\")\n",
    "print(f\"test size: {len(sequences) - train_size}\")\n",
    "\n",
    "train_sequences = sequences[:train_size]\n",
    "test_sequences = sequences[train_size:]\n",
    "\n",
    "print(f\"train sequences: {len(train_sequences)}\")\n",
    "print(f\"test sequences: {len(test_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key parameters\n",
    "seq_length = 30\n",
    "feature_dim = 7  # Number of features\n",
    "hidden_dim = 128  # Hidden units in LSTM and RNN\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator: LSTM\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim, seq_length):\n",
    "        super(Generator, self).__init__()\n",
    "        self.lstm = nn.LSTM(feature_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, feature_dim)  # Map hidden_dim to feature_dim for each time step\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden_state = torch.zeros(1, x.size(0), hidden_dim).to(x.device)\n",
    "        cell_state = torch.zeros(1, x.size(0), hidden_dim).to(x.device)\n",
    "        output, _ = self.lstm(x, (hidden_state, cell_state))\n",
    "        output = self.fc(output)  # Apply fc to all time steps\n",
    "        return self.tanh(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator: RNN\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim, seq_length):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=feature_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * seq_length, 1)  # Match input size to (hidden_dim * seq_length)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_length, feature_dim)\n",
    "        rnn_out, _ = self.rnn(x)\n",
    "        flattened = rnn_out.contiguous().view(x.size(0), -1)  # Shape: (batch_size, hidden_dim * seq_length)\n",
    "        output = self.fc(flattened)\n",
    "        return self.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = Generator(feature_dim, hidden_dim, seq_length).to(device)\n",
    "discriminator = Discriminator(feature_dim, hidden_dim, seq_length).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.001)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2000], Loss D: 1.2641, Loss G: 0.7910\n",
      "Epoch [2/2000], Loss D: 0.6918, Loss G: 2.8669\n",
      "Epoch [3/2000], Loss D: 3.6182, Loss G: 0.9736\n",
      "Epoch [4/2000], Loss D: 2.3151, Loss G: 0.4366\n",
      "Epoch [5/2000], Loss D: 1.6576, Loss G: 1.1414\n",
      "Epoch [6/2000], Loss D: 1.2847, Loss G: 1.8522\n",
      "Epoch [7/2000], Loss D: 0.9340, Loss G: 1.9905\n",
      "Epoch [8/2000], Loss D: 0.6388, Loss G: 1.8997\n",
      "Epoch [9/2000], Loss D: 0.4571, Loss G: 1.8326\n",
      "Epoch [10/2000], Loss D: 0.4789, Loss G: 1.5192\n",
      "Epoch [11/2000], Loss D: 1.0880, Loss G: 0.7317\n",
      "Epoch [12/2000], Loss D: 1.5019, Loss G: 0.6903\n",
      "Epoch [13/2000], Loss D: 1.8522, Loss G: 0.8674\n",
      "Epoch [14/2000], Loss D: 1.7567, Loss G: 0.6020\n",
      "Epoch [15/2000], Loss D: 1.3363, Loss G: 0.7210\n",
      "Epoch [16/2000], Loss D: 0.7740, Loss G: 1.5168\n",
      "Epoch [17/2000], Loss D: 0.3348, Loss G: 2.9052\n",
      "Epoch [18/2000], Loss D: 1.2663, Loss G: 11.2472\n",
      "Epoch [19/2000], Loss D: 88.0023, Loss G: 0.0000\n",
      "Epoch [20/2000], Loss D: 99.4746, Loss G: 0.0000\n",
      "Epoch [21/2000], Loss D: 25.8329, Loss G: 0.0048\n",
      "Epoch [22/2000], Loss D: 2.4875, Loss G: 4.2673\n",
      "Epoch [23/2000], Loss D: 0.6220, Loss G: 3.4974\n",
      "Epoch [24/2000], Loss D: 1.1787, Loss G: 1.9909\n",
      "Epoch [25/2000], Loss D: 1.7598, Loss G: 1.6307\n",
      "Epoch [26/2000], Loss D: 0.9049, Loss G: 2.8552\n",
      "Epoch [27/2000], Loss D: 0.2779, Loss G: 3.8490\n",
      "Epoch [28/2000], Loss D: 0.3613, Loss G: 2.5850\n",
      "Epoch [29/2000], Loss D: 0.1337, Loss G: 4.8809\n",
      "Epoch [30/2000], Loss D: 0.1853, Loss G: 3.8705\n",
      "Epoch [31/2000], Loss D: 0.0457, Loss G: 4.8034\n",
      "Epoch [32/2000], Loss D: 0.0191, Loss G: 5.1227\n",
      "Epoch [33/2000], Loss D: 0.0824, Loss G: 3.5232\n",
      "Epoch [34/2000], Loss D: 0.2646, Loss G: 3.5522\n",
      "Epoch [35/2000], Loss D: 0.4891, Loss G: 3.2754\n",
      "Epoch [36/2000], Loss D: 0.1046, Loss G: 4.6709\n",
      "Epoch [37/2000], Loss D: 0.0155, Loss G: 6.0778\n",
      "Epoch [38/2000], Loss D: 0.0028, Loss G: 7.2521\n",
      "Epoch [39/2000], Loss D: 0.7810, Loss G: 4.4777\n",
      "Epoch [40/2000], Loss D: 1.8413, Loss G: 2.5481\n",
      "Epoch [41/2000], Loss D: 2.0339, Loss G: 2.1211\n",
      "Epoch [42/2000], Loss D: 3.1845, Loss G: 1.3135\n",
      "Epoch [43/2000], Loss D: 2.4137, Loss G: 1.5194\n",
      "Epoch [44/2000], Loss D: 1.5477, Loss G: 1.2000\n",
      "Epoch [45/2000], Loss D: 1.3125, Loss G: 1.5981\n",
      "Epoch [46/2000], Loss D: 0.7293, Loss G: 2.7163\n",
      "Epoch [47/2000], Loss D: 3.4470, Loss G: 5.1512\n",
      "Epoch [48/2000], Loss D: 3.1943, Loss G: 1.3148\n",
      "Epoch [49/2000], Loss D: 2.5679, Loss G: 0.8441\n",
      "Epoch [50/2000], Loss D: 2.0445, Loss G: 0.5630\n",
      "Epoch [51/2000], Loss D: 1.4624, Loss G: 1.2294\n",
      "Epoch [52/2000], Loss D: 1.1971, Loss G: 0.8516\n",
      "Epoch [53/2000], Loss D: 1.2501, Loss G: 1.0556\n",
      "Epoch [54/2000], Loss D: 1.3191, Loss G: 0.9280\n",
      "Epoch [55/2000], Loss D: 1.3407, Loss G: 0.8346\n",
      "Epoch [56/2000], Loss D: 1.1247, Loss G: 1.1484\n",
      "Epoch [57/2000], Loss D: 1.0062, Loss G: 1.0492\n",
      "Epoch [58/2000], Loss D: 0.8439, Loss G: 1.2598\n",
      "Epoch [59/2000], Loss D: 0.7316, Loss G: 1.2718\n",
      "Epoch [60/2000], Loss D: 0.7143, Loss G: 1.2667\n",
      "Epoch [61/2000], Loss D: 0.6018, Loss G: 1.4304\n",
      "Epoch [62/2000], Loss D: 0.5397, Loss G: 1.5745\n",
      "Epoch [63/2000], Loss D: 0.6602, Loss G: 1.4441\n",
      "Epoch [64/2000], Loss D: 0.8030, Loss G: 1.2721\n",
      "Epoch [65/2000], Loss D: 0.8971, Loss G: 1.1651\n",
      "Epoch [66/2000], Loss D: 1.0161, Loss G: 1.0112\n",
      "Epoch [67/2000], Loss D: 1.0702, Loss G: 1.0115\n",
      "Epoch [68/2000], Loss D: 1.3382, Loss G: 1.1755\n",
      "Epoch [69/2000], Loss D: 2.1368, Loss G: 1.0450\n",
      "Epoch [70/2000], Loss D: 2.5211, Loss G: 0.5606\n",
      "Epoch [71/2000], Loss D: 2.0452, Loss G: 0.7517\n",
      "Epoch [72/2000], Loss D: 2.0437, Loss G: 0.4686\n",
      "Epoch [73/2000], Loss D: 2.0113, Loss G: 0.6057\n",
      "Epoch [74/2000], Loss D: 1.8883, Loss G: 0.6747\n",
      "Epoch [75/2000], Loss D: 1.9616, Loss G: 0.6194\n",
      "Epoch [76/2000], Loss D: 1.9291, Loss G: 0.6457\n",
      "Epoch [77/2000], Loss D: 1.7441, Loss G: 0.6775\n",
      "Epoch [78/2000], Loss D: 1.6494, Loss G: 0.7713\n",
      "Epoch [79/2000], Loss D: 1.6140, Loss G: 0.8110\n",
      "Epoch [80/2000], Loss D: 1.5522, Loss G: 0.8403\n",
      "Epoch [81/2000], Loss D: 1.5057, Loss G: 0.8360\n",
      "Epoch [82/2000], Loss D: 1.5772, Loss G: 0.9299\n",
      "Epoch [83/2000], Loss D: 1.6802, Loss G: 0.9596\n",
      "Epoch [84/2000], Loss D: 1.5665, Loss G: 0.8781\n",
      "Epoch [85/2000], Loss D: 1.4190, Loss G: 0.7636\n",
      "Epoch [86/2000], Loss D: 1.3937, Loss G: 1.0913\n",
      "Epoch [87/2000], Loss D: 1.3015, Loss G: 0.8375\n",
      "Epoch [88/2000], Loss D: 1.2031, Loss G: 0.9963\n",
      "Epoch [89/2000], Loss D: 1.8821, Loss G: 0.7681\n",
      "Epoch [90/2000], Loss D: 2.2656, Loss G: 0.4366\n",
      "Epoch [91/2000], Loss D: 2.0284, Loss G: 0.6208\n",
      "Epoch [92/2000], Loss D: 1.7693, Loss G: 0.7369\n",
      "Epoch [93/2000], Loss D: 1.3430, Loss G: 0.8229\n",
      "Epoch [94/2000], Loss D: 1.0980, Loss G: 1.0878\n",
      "Epoch [95/2000], Loss D: 0.7996, Loss G: 1.3210\n",
      "Epoch [96/2000], Loss D: 0.7326, Loss G: 1.5032\n",
      "Epoch [97/2000], Loss D: 0.5341, Loss G: 1.6892\n",
      "Epoch [98/2000], Loss D: 0.4055, Loss G: 2.2666\n",
      "Epoch [99/2000], Loss D: 0.4241, Loss G: 2.1743\n",
      "Epoch [100/2000], Loss D: 0.4615, Loss G: 2.0033\n",
      "Epoch [101/2000], Loss D: 0.4743, Loss G: 2.0009\n",
      "Epoch [102/2000], Loss D: 0.5043, Loss G: 2.2391\n",
      "Epoch [103/2000], Loss D: 0.6630, Loss G: 1.9436\n",
      "Epoch [104/2000], Loss D: 0.9506, Loss G: 1.7547\n",
      "Epoch [105/2000], Loss D: 1.4356, Loss G: 1.6060\n",
      "Epoch [106/2000], Loss D: 1.6922, Loss G: 1.0963\n",
      "Epoch [107/2000], Loss D: 1.6903, Loss G: 1.5929\n",
      "Epoch [108/2000], Loss D: 1.7518, Loss G: 2.2407\n",
      "Epoch [109/2000], Loss D: 1.5202, Loss G: 2.9568\n",
      "Epoch [110/2000], Loss D: 1.0310, Loss G: 4.4770\n",
      "Epoch [111/2000], Loss D: 2.2655, Loss G: 4.5727\n",
      "Epoch [112/2000], Loss D: 5.4577, Loss G: 1.6307\n",
      "Epoch [113/2000], Loss D: 6.7162, Loss G: 1.8716\n",
      "Epoch [114/2000], Loss D: 1.9794, Loss G: 2.1427\n",
      "Epoch [115/2000], Loss D: 1.8263, Loss G: 2.5950\n",
      "Epoch [116/2000], Loss D: 1.1336, Loss G: 2.9591\n",
      "Epoch [117/2000], Loss D: 0.6633, Loss G: 2.1116\n",
      "Epoch [118/2000], Loss D: 0.4598, Loss G: 4.3182\n",
      "Epoch [119/2000], Loss D: 0.2170, Loss G: 1.7988\n",
      "Epoch [120/2000], Loss D: 0.1104, Loss G: 4.2259\n",
      "Epoch [121/2000], Loss D: 0.1029, Loss G: 5.6671\n",
      "Epoch [122/2000], Loss D: 0.1187, Loss G: 5.0416\n",
      "Epoch [123/2000], Loss D: 0.2215, Loss G: 5.0472\n",
      "Epoch [124/2000], Loss D: 0.3700, Loss G: 5.0836\n",
      "Epoch [125/2000], Loss D: 0.3391, Loss G: 3.8539\n",
      "Epoch [126/2000], Loss D: 0.4478, Loss G: 3.1753\n",
      "Epoch [127/2000], Loss D: 0.3891, Loss G: 2.4904\n",
      "Epoch [128/2000], Loss D: 0.3566, Loss G: 2.2392\n",
      "Epoch [129/2000], Loss D: 0.3936, Loss G: 1.9809\n",
      "Epoch [130/2000], Loss D: 0.4819, Loss G: 1.7706\n",
      "Epoch [131/2000], Loss D: 0.6006, Loss G: 1.6752\n",
      "Epoch [132/2000], Loss D: 0.6873, Loss G: 1.6349\n",
      "Epoch [133/2000], Loss D: 1.0074, Loss G: 1.3164\n",
      "Epoch [134/2000], Loss D: 2.2130, Loss G: 0.9188\n",
      "Epoch [135/2000], Loss D: 4.0597, Loss G: 0.5573\n",
      "Epoch [136/2000], Loss D: 3.7340, Loss G: 0.2674\n",
      "Epoch [137/2000], Loss D: 3.0958, Loss G: 0.5811\n",
      "Epoch [138/2000], Loss D: 2.4107, Loss G: 0.4743\n",
      "Epoch [139/2000], Loss D: 2.0382, Loss G: 0.5322\n",
      "Epoch [140/2000], Loss D: 1.6806, Loss G: 0.7108\n",
      "Epoch [141/2000], Loss D: 1.4470, Loss G: 0.7145\n",
      "Epoch [142/2000], Loss D: 1.2452, Loss G: 0.7922\n",
      "Epoch [143/2000], Loss D: 1.1111, Loss G: 0.9689\n",
      "Epoch [144/2000], Loss D: 0.9546, Loss G: 1.0375\n",
      "Epoch [145/2000], Loss D: 0.8545, Loss G: 1.1044\n",
      "Epoch [146/2000], Loss D: 0.7524, Loss G: 1.2466\n",
      "Epoch [147/2000], Loss D: 0.6971, Loss G: 1.3053\n",
      "Epoch [148/2000], Loss D: 0.6421, Loss G: 1.3585\n",
      "Epoch [149/2000], Loss D: 0.6448, Loss G: 1.3906\n",
      "Epoch [150/2000], Loss D: 0.8109, Loss G: 1.2419\n",
      "Epoch [151/2000], Loss D: 1.0505, Loss G: 1.0103\n",
      "Epoch [152/2000], Loss D: 1.1391, Loss G: 1.0311\n",
      "Epoch [153/2000], Loss D: 1.4994, Loss G: 1.0485\n",
      "Epoch [154/2000], Loss D: 1.8042, Loss G: 0.8660\n",
      "Epoch [155/2000], Loss D: 2.1035, Loss G: 0.5061\n",
      "Epoch [156/2000], Loss D: 2.0447, Loss G: 0.4815\n",
      "Epoch [157/2000], Loss D: 1.8680, Loss G: 0.8569\n",
      "Epoch [158/2000], Loss D: 1.6117, Loss G: 0.8059\n",
      "Epoch [159/2000], Loss D: 1.7912, Loss G: 1.1553\n",
      "Epoch [160/2000], Loss D: 2.0866, Loss G: 0.9893\n",
      "Epoch [161/2000], Loss D: 1.8672, Loss G: 0.5346\n",
      "Epoch [162/2000], Loss D: 1.5037, Loss G: 0.9322\n",
      "Epoch [163/2000], Loss D: 1.5260, Loss G: 0.8375\n",
      "Epoch [164/2000], Loss D: 1.5717, Loss G: 0.6961\n",
      "Epoch [165/2000], Loss D: 1.4230, Loss G: 0.6874\n",
      "Epoch [166/2000], Loss D: 1.3012, Loss G: 0.8698\n",
      "Epoch [167/2000], Loss D: 1.2993, Loss G: 0.8683\n",
      "Epoch [168/2000], Loss D: 1.1051, Loss G: 1.0216\n",
      "Epoch [169/2000], Loss D: 1.1052, Loss G: 1.4691\n",
      "Epoch [170/2000], Loss D: 1.2394, Loss G: 1.2000\n",
      "Epoch [171/2000], Loss D: 1.2318, Loss G: 0.9847\n",
      "Epoch [172/2000], Loss D: 1.2245, Loss G: 1.4283\n",
      "Epoch [173/2000], Loss D: 1.0457, Loss G: 0.8146\n",
      "Epoch [174/2000], Loss D: 0.9684, Loss G: 1.2002\n",
      "Epoch [175/2000], Loss D: 0.8713, Loss G: 1.2886\n",
      "Epoch [176/2000], Loss D: 0.9920, Loss G: 1.0464\n",
      "Epoch [177/2000], Loss D: 1.0610, Loss G: 1.0097\n",
      "Epoch [178/2000], Loss D: 1.0314, Loss G: 1.0665\n",
      "Epoch [179/2000], Loss D: 1.0644, Loss G: 0.9522\n",
      "Epoch [180/2000], Loss D: 1.1634, Loss G: 0.8747\n",
      "Epoch [181/2000], Loss D: 1.2553, Loss G: 0.8550\n",
      "Epoch [182/2000], Loss D: 1.3157, Loss G: 0.7963\n",
      "Epoch [183/2000], Loss D: 1.3619, Loss G: 0.7531\n",
      "Epoch [184/2000], Loss D: 1.2742, Loss G: 0.8131\n",
      "Epoch [185/2000], Loss D: 1.3588, Loss G: 0.9865\n",
      "Epoch [186/2000], Loss D: 1.5154, Loss G: 1.1128\n",
      "Epoch [187/2000], Loss D: 1.5415, Loss G: 1.1764\n",
      "Epoch [188/2000], Loss D: 1.6777, Loss G: 1.1475\n",
      "Epoch [189/2000], Loss D: 1.6346, Loss G: 0.8168\n",
      "Epoch [190/2000], Loss D: 1.8225, Loss G: 0.5955\n",
      "Epoch [191/2000], Loss D: 2.1370, Loss G: 0.5816\n",
      "Epoch [192/2000], Loss D: 2.1558, Loss G: 0.6324\n",
      "Epoch [193/2000], Loss D: 1.9899, Loss G: 0.4692\n",
      "Epoch [194/2000], Loss D: 1.6545, Loss G: 0.6206\n",
      "Epoch [195/2000], Loss D: 1.2832, Loss G: 1.1098\n",
      "Epoch [196/2000], Loss D: 1.2208, Loss G: 1.0395\n",
      "Epoch [197/2000], Loss D: 1.4583, Loss G: 0.8628\n",
      "Epoch [198/2000], Loss D: 1.4365, Loss G: 0.9595\n",
      "Epoch [199/2000], Loss D: 1.9613, Loss G: 0.9647\n",
      "Epoch [200/2000], Loss D: 2.1416, Loss G: 0.9643\n",
      "Epoch [201/2000], Loss D: 2.3764, Loss G: 0.9621\n",
      "Epoch [202/2000], Loss D: 2.1695, Loss G: 0.7481\n",
      "Epoch [203/2000], Loss D: 1.8309, Loss G: 0.9707\n",
      "Epoch [204/2000], Loss D: 1.2485, Loss G: 1.1531\n",
      "Epoch [205/2000], Loss D: 1.1194, Loss G: 0.9037\n",
      "Epoch [206/2000], Loss D: 0.8284, Loss G: 1.2192\n",
      "Epoch [207/2000], Loss D: 0.6969, Loss G: 1.4023\n",
      "Epoch [208/2000], Loss D: 0.5594, Loss G: 1.5771\n",
      "Epoch [209/2000], Loss D: 0.5403, Loss G: 1.6661\n",
      "Epoch [210/2000], Loss D: 0.6050, Loss G: 1.5580\n",
      "Epoch [211/2000], Loss D: 0.7143, Loss G: 1.2076\n",
      "Epoch [212/2000], Loss D: 0.7271, Loss G: 1.4120\n",
      "Epoch [213/2000], Loss D: 0.7938, Loss G: 1.4769\n",
      "Epoch [214/2000], Loss D: 0.8179, Loss G: 1.2640\n",
      "Epoch [215/2000], Loss D: 0.9254, Loss G: 1.2116\n",
      "Epoch [216/2000], Loss D: 1.0712, Loss G: 1.0134\n",
      "Epoch [217/2000], Loss D: 1.1876, Loss G: 0.8255\n",
      "Epoch [218/2000], Loss D: 1.3364, Loss G: 0.7909\n",
      "Epoch [219/2000], Loss D: 1.4451, Loss G: 0.7657\n",
      "Epoch [220/2000], Loss D: 1.5011, Loss G: 0.8160\n",
      "Epoch [221/2000], Loss D: 1.6242, Loss G: 0.6155\n",
      "Epoch [222/2000], Loss D: 1.7523, Loss G: 0.6054\n",
      "Epoch [223/2000], Loss D: 1.7177, Loss G: 0.6427\n",
      "Epoch [224/2000], Loss D: 1.7374, Loss G: 0.5970\n",
      "Epoch [225/2000], Loss D: 1.7611, Loss G: 0.6010\n",
      "Epoch [226/2000], Loss D: 1.6505, Loss G: 1.0666\n",
      "Epoch [227/2000], Loss D: 2.0486, Loss G: 0.6871\n",
      "Epoch [228/2000], Loss D: 1.4214, Loss G: 0.9211\n",
      "Epoch [229/2000], Loss D: 1.7691, Loss G: 0.6057\n",
      "Epoch [230/2000], Loss D: 1.9433, Loss G: 0.6749\n",
      "Epoch [231/2000], Loss D: 1.5550, Loss G: 0.6123\n",
      "Epoch [232/2000], Loss D: 1.5000, Loss G: 0.8103\n",
      "Epoch [233/2000], Loss D: 1.5026, Loss G: 1.5321\n",
      "Epoch [234/2000], Loss D: 1.8186, Loss G: 0.7858\n",
      "Epoch [235/2000], Loss D: 1.4469, Loss G: 0.8566\n",
      "Epoch [236/2000], Loss D: 1.1744, Loss G: 0.8774\n",
      "Epoch [237/2000], Loss D: 1.3636, Loss G: 0.8420\n",
      "Epoch [238/2000], Loss D: 1.1982, Loss G: 0.9001\n",
      "Epoch [239/2000], Loss D: 1.6482, Loss G: 0.7563\n",
      "Epoch [240/2000], Loss D: 0.9478, Loss G: 0.8697\n",
      "Epoch [241/2000], Loss D: 0.9410, Loss G: 1.7804\n",
      "Epoch [242/2000], Loss D: 1.1415, Loss G: 1.3035\n",
      "Epoch [243/2000], Loss D: 1.0446, Loss G: 1.1916\n",
      "Epoch [244/2000], Loss D: 0.9278, Loss G: 1.7023\n",
      "Epoch [245/2000], Loss D: 0.6934, Loss G: 1.3026\n",
      "Epoch [246/2000], Loss D: 0.6476, Loss G: 1.9366\n",
      "Epoch [247/2000], Loss D: 1.2084, Loss G: 1.1430\n",
      "Epoch [248/2000], Loss D: 1.6315, Loss G: 0.5829\n",
      "Epoch [249/2000], Loss D: 1.2442, Loss G: 1.1027\n",
      "Epoch [250/2000], Loss D: 1.6894, Loss G: 0.9615\n",
      "Epoch [251/2000], Loss D: 4.2959, Loss G: 0.6261\n",
      "Epoch [252/2000], Loss D: 5.3204, Loss G: 1.7216\n",
      "Epoch [253/2000], Loss D: 2.3378, Loss G: 1.6462\n",
      "Epoch [254/2000], Loss D: 0.3167, Loss G: 7.9250\n",
      "Epoch [255/2000], Loss D: 2.1666, Loss G: 8.9344\n",
      "Epoch [256/2000], Loss D: 3.0124, Loss G: 1.7682\n",
      "Epoch [257/2000], Loss D: 2.5765, Loss G: 0.5525\n",
      "Epoch [258/2000], Loss D: 2.1572, Loss G: 1.3381\n",
      "Epoch [259/2000], Loss D: 1.9161, Loss G: 0.4241\n",
      "Epoch [260/2000], Loss D: 1.8291, Loss G: 0.9107\n",
      "Epoch [261/2000], Loss D: 1.7757, Loss G: 0.6544\n",
      "Epoch [262/2000], Loss D: 1.6677, Loss G: 0.5571\n",
      "Epoch [263/2000], Loss D: 1.6467, Loss G: 0.7678\n",
      "Epoch [264/2000], Loss D: 1.5924, Loss G: 0.6343\n",
      "Epoch [265/2000], Loss D: 1.5156, Loss G: 0.6586\n",
      "Epoch [266/2000], Loss D: 1.4485, Loss G: 0.8045\n",
      "Epoch [267/2000], Loss D: 1.3584, Loss G: 0.7563\n",
      "Epoch [268/2000], Loss D: 1.3747, Loss G: 0.7676\n",
      "Epoch [269/2000], Loss D: 1.3391, Loss G: 0.8448\n",
      "Epoch [270/2000], Loss D: 1.3236, Loss G: 0.8726\n",
      "Epoch [271/2000], Loss D: 1.3314, Loss G: 0.8156\n",
      "Epoch [272/2000], Loss D: 1.2920, Loss G: 0.8256\n",
      "Epoch [273/2000], Loss D: 1.2708, Loss G: 0.8495\n",
      "Epoch [274/2000], Loss D: 1.2752, Loss G: 0.8599\n",
      "Epoch [275/2000], Loss D: 1.2642, Loss G: 0.8699\n",
      "Epoch [276/2000], Loss D: 1.2364, Loss G: 0.8732\n",
      "Epoch [277/2000], Loss D: 1.2281, Loss G: 0.8696\n",
      "Epoch [278/2000], Loss D: 1.2023, Loss G: 0.8663\n",
      "Epoch [279/2000], Loss D: 1.2490, Loss G: 0.8476\n",
      "Epoch [280/2000], Loss D: 1.2283, Loss G: 0.8593\n",
      "Epoch [281/2000], Loss D: 1.2227, Loss G: 0.8627\n",
      "Epoch [282/2000], Loss D: 1.2336, Loss G: 0.8617\n",
      "Epoch [283/2000], Loss D: 1.2068, Loss G: 0.8950\n",
      "Epoch [284/2000], Loss D: 1.2480, Loss G: 0.8652\n",
      "Epoch [285/2000], Loss D: 1.2464, Loss G: 0.8368\n",
      "Epoch [286/2000], Loss D: 1.2879, Loss G: 0.8625\n",
      "Epoch [287/2000], Loss D: 1.2602, Loss G: 0.8507\n",
      "Epoch [288/2000], Loss D: 1.2462, Loss G: 0.8615\n",
      "Epoch [289/2000], Loss D: 1.2826, Loss G: 0.8605\n",
      "Epoch [290/2000], Loss D: 1.2995, Loss G: 0.8109\n",
      "Epoch [291/2000], Loss D: 1.3126, Loss G: 0.8371\n",
      "Epoch [292/2000], Loss D: 1.3598, Loss G: 0.7897\n",
      "Epoch [293/2000], Loss D: 1.3953, Loss G: 0.7694\n",
      "Epoch [294/2000], Loss D: 1.4666, Loss G: 0.7394\n",
      "Epoch [295/2000], Loss D: 1.5449, Loss G: 0.6839\n",
      "Epoch [296/2000], Loss D: 1.7195, Loss G: 0.6003\n",
      "Epoch [297/2000], Loss D: 1.7948, Loss G: 0.5883\n",
      "Epoch [298/2000], Loss D: 1.8583, Loss G: 0.5587\n",
      "Epoch [299/2000], Loss D: 1.8865, Loss G: 0.5541\n",
      "Epoch [300/2000], Loss D: 1.8105, Loss G: 0.6313\n",
      "Epoch [301/2000], Loss D: 2.0898, Loss G: 1.2090\n",
      "Epoch [302/2000], Loss D: 9.6052, Loss G: 0.0087\n",
      "Epoch [303/2000], Loss D: 4.0655, Loss G: 0.9359\n",
      "Epoch [304/2000], Loss D: 1.5672, Loss G: 0.8725\n",
      "Epoch [305/2000], Loss D: 1.7088, Loss G: 0.7427\n",
      "Epoch [306/2000], Loss D: 1.7303, Loss G: 0.6353\n",
      "Epoch [307/2000], Loss D: 1.8299, Loss G: 0.5903\n",
      "Epoch [308/2000], Loss D: 2.0013, Loss G: 0.5754\n",
      "Epoch [309/2000], Loss D: 1.9614, Loss G: 0.5881\n",
      "Epoch [310/2000], Loss D: 1.7619, Loss G: 0.7659\n",
      "Epoch [311/2000], Loss D: 1.3936, Loss G: 0.7509\n",
      "Epoch [312/2000], Loss D: 1.0374, Loss G: 0.9907\n",
      "Epoch [313/2000], Loss D: 1.0483, Loss G: 1.3324\n",
      "Epoch [314/2000], Loss D: 0.9558, Loss G: 1.9401\n",
      "Epoch [315/2000], Loss D: 1.5924, Loss G: 0.9591\n",
      "Epoch [316/2000], Loss D: 1.8168, Loss G: 1.0766\n",
      "Epoch [317/2000], Loss D: 1.7691, Loss G: 0.6684\n",
      "Epoch [318/2000], Loss D: 0.7262, Loss G: 1.6494\n",
      "Epoch [319/2000], Loss D: 0.3491, Loss G: 1.9092\n",
      "Epoch [320/2000], Loss D: 0.3878, Loss G: 2.5205\n",
      "Epoch [321/2000], Loss D: 0.9095, Loss G: 1.9085\n",
      "Epoch [322/2000], Loss D: 1.2186, Loss G: 1.1227\n",
      "Epoch [323/2000], Loss D: 1.3748, Loss G: 0.8877\n",
      "Epoch [324/2000], Loss D: 1.2044, Loss G: 0.7494\n",
      "Epoch [325/2000], Loss D: 0.9982, Loss G: 1.2887\n",
      "Epoch [326/2000], Loss D: 0.9536, Loss G: 1.4639\n",
      "Epoch [327/2000], Loss D: 1.0009, Loss G: 1.5268\n",
      "Epoch [328/2000], Loss D: 1.5744, Loss G: 1.6146\n",
      "Epoch [329/2000], Loss D: 1.5441, Loss G: 0.5132\n",
      "Epoch [330/2000], Loss D: 1.2887, Loss G: 1.2979\n",
      "Epoch [331/2000], Loss D: 1.4313, Loss G: 1.2560\n",
      "Epoch [332/2000], Loss D: 1.4039, Loss G: 1.2168\n",
      "Epoch [333/2000], Loss D: 1.3784, Loss G: 0.9253\n",
      "Epoch [334/2000], Loss D: 1.1571, Loss G: 1.0659\n",
      "Epoch [335/2000], Loss D: 0.9926, Loss G: 0.9011\n",
      "Epoch [336/2000], Loss D: 0.9324, Loss G: 1.1224\n",
      "Epoch [337/2000], Loss D: 1.0432, Loss G: 1.1094\n",
      "Epoch [338/2000], Loss D: 1.1800, Loss G: 0.9488\n",
      "Epoch [339/2000], Loss D: 1.4449, Loss G: 0.8220\n",
      "Epoch [340/2000], Loss D: 1.6135, Loss G: 0.8125\n",
      "Epoch [341/2000], Loss D: 1.4509, Loss G: 0.8880\n",
      "Epoch [342/2000], Loss D: 1.6020, Loss G: 0.8047\n",
      "Epoch [343/2000], Loss D: 1.3229, Loss G: 1.0414\n",
      "Epoch [344/2000], Loss D: 1.8900, Loss G: 0.6845\n",
      "Epoch [345/2000], Loss D: 2.3039, Loss G: 1.1321\n",
      "Epoch [346/2000], Loss D: 2.0726, Loss G: 1.0194\n",
      "Epoch [347/2000], Loss D: 1.7205, Loss G: 0.8523\n",
      "Epoch [348/2000], Loss D: 1.5612, Loss G: 0.8765\n",
      "Epoch [349/2000], Loss D: 1.8712, Loss G: 1.0006\n",
      "Epoch [350/2000], Loss D: 1.6352, Loss G: 0.7976\n",
      "Epoch [351/2000], Loss D: 1.1952, Loss G: 0.8073\n",
      "Epoch [352/2000], Loss D: 0.8330, Loss G: 1.8405\n",
      "Epoch [353/2000], Loss D: 1.8376, Loss G: 1.6822\n",
      "Epoch [354/2000], Loss D: 1.6341, Loss G: 0.5139\n",
      "Epoch [355/2000], Loss D: 1.5681, Loss G: 0.8779\n",
      "Epoch [356/2000], Loss D: 1.5652, Loss G: 0.6063\n",
      "Epoch [357/2000], Loss D: 1.4473, Loss G: 0.8420\n",
      "Epoch [358/2000], Loss D: 1.4106, Loss G: 1.0260\n",
      "Epoch [359/2000], Loss D: 1.6731, Loss G: 1.0124\n",
      "Epoch [360/2000], Loss D: 2.2618, Loss G: 0.8184\n",
      "Epoch [361/2000], Loss D: 2.1837, Loss G: 0.7433\n",
      "Epoch [362/2000], Loss D: 1.6112, Loss G: 1.3211\n",
      "Epoch [363/2000], Loss D: 1.4606, Loss G: 1.1251\n",
      "Epoch [364/2000], Loss D: 1.4743, Loss G: 0.9752\n",
      "Epoch [365/2000], Loss D: 1.4189, Loss G: 1.0666\n",
      "Epoch [366/2000], Loss D: 1.3453, Loss G: 1.2133\n",
      "Epoch [367/2000], Loss D: 1.3780, Loss G: 1.2648\n",
      "Epoch [368/2000], Loss D: 1.5967, Loss G: 1.2627\n",
      "Epoch [369/2000], Loss D: 1.5435, Loss G: 0.8691\n",
      "Epoch [370/2000], Loss D: 1.3986, Loss G: 0.5993\n",
      "Epoch [371/2000], Loss D: 1.3620, Loss G: 0.8973\n",
      "Epoch [372/2000], Loss D: 1.3248, Loss G: 0.7686\n",
      "Epoch [373/2000], Loss D: 1.2972, Loss G: 0.7391\n",
      "Epoch [374/2000], Loss D: 1.2886, Loss G: 0.8584\n",
      "Epoch [375/2000], Loss D: 1.3167, Loss G: 0.7879\n",
      "Epoch [376/2000], Loss D: 1.4137, Loss G: 0.7436\n",
      "Epoch [377/2000], Loss D: 1.4880, Loss G: 0.7625\n",
      "Epoch [378/2000], Loss D: 1.5756, Loss G: 0.7059\n",
      "Epoch [379/2000], Loss D: 1.4934, Loss G: 0.7048\n",
      "Epoch [380/2000], Loss D: 1.3608, Loss G: 0.7949\n",
      "Epoch [381/2000], Loss D: 1.1999, Loss G: 0.8299\n",
      "Epoch [382/2000], Loss D: 1.2068, Loss G: 0.9418\n",
      "Epoch [383/2000], Loss D: 1.5181, Loss G: 1.0047\n",
      "Epoch [384/2000], Loss D: 1.5972, Loss G: 1.1681\n",
      "Epoch [385/2000], Loss D: 1.3877, Loss G: 0.5808\n",
      "Epoch [386/2000], Loss D: 1.3183, Loss G: 0.9216\n",
      "Epoch [387/2000], Loss D: 1.2024, Loss G: 0.9240\n",
      "Epoch [388/2000], Loss D: 1.1047, Loss G: 0.8879\n",
      "Epoch [389/2000], Loss D: 1.1367, Loss G: 0.9981\n",
      "Epoch [390/2000], Loss D: 1.3354, Loss G: 1.0405\n",
      "Epoch [391/2000], Loss D: 1.5920, Loss G: 1.0054\n",
      "Epoch [392/2000], Loss D: 1.7451, Loss G: 0.8142\n",
      "Epoch [393/2000], Loss D: 1.5384, Loss G: 0.7856\n",
      "Epoch [394/2000], Loss D: 1.0666, Loss G: 1.1628\n",
      "Epoch [395/2000], Loss D: 0.8330, Loss G: 1.3397\n",
      "Epoch [396/2000], Loss D: 0.7420, Loss G: 1.1997\n",
      "Epoch [397/2000], Loss D: 1.0193, Loss G: 1.3029\n",
      "Epoch [398/2000], Loss D: 1.5154, Loss G: 1.1915\n",
      "Epoch [399/2000], Loss D: 1.5665, Loss G: 0.7684\n",
      "Epoch [400/2000], Loss D: 1.4817, Loss G: 0.6291\n",
      "Epoch [401/2000], Loss D: 1.3241, Loss G: 0.9729\n",
      "Epoch [402/2000], Loss D: 1.2106, Loss G: 0.9027\n",
      "Epoch [403/2000], Loss D: 1.1562, Loss G: 1.3095\n",
      "Epoch [404/2000], Loss D: 1.3397, Loss G: 1.6802\n",
      "Epoch [405/2000], Loss D: 1.8957, Loss G: 0.7158\n",
      "Epoch [406/2000], Loss D: 1.9217, Loss G: 0.9604\n",
      "Epoch [407/2000], Loss D: 1.7182, Loss G: 1.0388\n",
      "Epoch [408/2000], Loss D: 2.0985, Loss G: 0.6468\n",
      "Epoch [409/2000], Loss D: 2.2716, Loss G: 0.7662\n",
      "Epoch [410/2000], Loss D: 2.1302, Loss G: 0.7040\n",
      "Epoch [411/2000], Loss D: 2.0629, Loss G: 0.6225\n",
      "Epoch [412/2000], Loss D: 1.7028, Loss G: 0.6535\n",
      "Epoch [413/2000], Loss D: 1.3695, Loss G: 0.8434\n",
      "Epoch [414/2000], Loss D: 1.2354, Loss G: 0.9455\n",
      "Epoch [415/2000], Loss D: 1.5420, Loss G: 1.2613\n",
      "Epoch [416/2000], Loss D: 1.5333, Loss G: 1.0653\n",
      "Epoch [417/2000], Loss D: 1.7858, Loss G: 0.7624\n",
      "Epoch [418/2000], Loss D: 1.4020, Loss G: 1.2521\n",
      "Epoch [419/2000], Loss D: 1.6997, Loss G: 1.2026\n",
      "Epoch [420/2000], Loss D: 2.2211, Loss G: 1.0541\n",
      "Epoch [421/2000], Loss D: 1.8865, Loss G: 0.8697\n",
      "Epoch [422/2000], Loss D: 2.2530, Loss G: 1.2124\n",
      "Epoch [423/2000], Loss D: 3.1850, Loss G: 2.3256\n",
      "Epoch [424/2000], Loss D: 1.9590, Loss G: 0.5003\n",
      "Epoch [425/2000], Loss D: 1.6743, Loss G: 1.0926\n",
      "Epoch [426/2000], Loss D: 2.4956, Loss G: 0.5979\n",
      "Epoch [427/2000], Loss D: 2.3362, Loss G: 0.8089\n",
      "Epoch [428/2000], Loss D: 1.5203, Loss G: 0.6525\n",
      "Epoch [429/2000], Loss D: 0.8029, Loss G: 1.3137\n",
      "Epoch [430/2000], Loss D: 0.8073, Loss G: 1.4991\n",
      "Epoch [431/2000], Loss D: 0.9309, Loss G: 1.1079\n",
      "Epoch [432/2000], Loss D: 0.9570, Loss G: 1.0081\n",
      "Epoch [433/2000], Loss D: 1.1185, Loss G: 1.1416\n",
      "Epoch [434/2000], Loss D: 1.3128, Loss G: 0.8402\n",
      "Epoch [435/2000], Loss D: 1.4319, Loss G: 0.7214\n",
      "Epoch [436/2000], Loss D: 1.4332, Loss G: 0.7559\n",
      "Epoch [437/2000], Loss D: 1.3859, Loss G: 0.8622\n",
      "Epoch [438/2000], Loss D: 1.4423, Loss G: 0.7766\n",
      "Epoch [439/2000], Loss D: 1.4400, Loss G: 0.7695\n",
      "Epoch [440/2000], Loss D: 1.1361, Loss G: 0.8599\n",
      "Epoch [441/2000], Loss D: 0.9037, Loss G: 1.2695\n",
      "Epoch [442/2000], Loss D: 0.6383, Loss G: 1.3020\n",
      "Epoch [443/2000], Loss D: 0.7916, Loss G: 1.4121\n",
      "Epoch [444/2000], Loss D: 1.0032, Loss G: 1.2598\n",
      "Epoch [445/2000], Loss D: 0.9901, Loss G: 0.9025\n",
      "Epoch [446/2000], Loss D: 1.0215, Loss G: 0.9896\n",
      "Epoch [447/2000], Loss D: 1.1363, Loss G: 1.0094\n",
      "Epoch [448/2000], Loss D: 1.6274, Loss G: 0.8720\n",
      "Epoch [449/2000], Loss D: 2.0266, Loss G: 0.4149\n",
      "Epoch [450/2000], Loss D: 3.1232, Loss G: 1.6937\n",
      "Epoch [451/2000], Loss D: 2.1815, Loss G: 0.3158\n",
      "Epoch [452/2000], Loss D: 1.6593, Loss G: 1.5180\n",
      "Epoch [453/2000], Loss D: 1.3379, Loss G: 0.8207\n",
      "Epoch [454/2000], Loss D: 1.2997, Loss G: 1.0116\n",
      "Epoch [455/2000], Loss D: 1.5950, Loss G: 0.7973\n",
      "Epoch [456/2000], Loss D: 2.1216, Loss G: 0.6699\n",
      "Epoch [457/2000], Loss D: 2.4137, Loss G: 0.5768\n",
      "Epoch [458/2000], Loss D: 3.4852, Loss G: 0.9628\n",
      "Epoch [459/2000], Loss D: 3.0994, Loss G: 0.3985\n",
      "Epoch [460/2000], Loss D: 2.1299, Loss G: 0.7288\n",
      "Epoch [461/2000], Loss D: 1.8256, Loss G: 1.1320\n",
      "Epoch [462/2000], Loss D: 1.3963, Loss G: 0.9923\n",
      "Epoch [463/2000], Loss D: 1.7631, Loss G: 1.1661\n",
      "Epoch [464/2000], Loss D: 2.1909, Loss G: 1.0811\n",
      "Epoch [465/2000], Loss D: 2.1112, Loss G: 0.6959\n",
      "Epoch [466/2000], Loss D: 1.5960, Loss G: 0.7383\n",
      "Epoch [467/2000], Loss D: 1.5339, Loss G: 0.8512\n",
      "Epoch [468/2000], Loss D: 1.7300, Loss G: 0.5526\n",
      "Epoch [469/2000], Loss D: 1.4281, Loss G: 0.9792\n",
      "Epoch [470/2000], Loss D: 0.8562, Loss G: 1.3415\n",
      "Epoch [471/2000], Loss D: 0.7279, Loss G: 2.0883\n",
      "Epoch [472/2000], Loss D: 1.7615, Loss G: 0.8388\n",
      "Epoch [473/2000], Loss D: 1.4112, Loss G: 1.6636\n",
      "Epoch [474/2000], Loss D: 1.0642, Loss G: 1.1339\n",
      "Epoch [475/2000], Loss D: 0.8952, Loss G: 1.3194\n",
      "Epoch [476/2000], Loss D: 1.0827, Loss G: 0.8953\n",
      "Epoch [477/2000], Loss D: 1.2306, Loss G: 1.4424\n",
      "Epoch [478/2000], Loss D: 1.1912, Loss G: 0.9017\n",
      "Epoch [479/2000], Loss D: 0.8846, Loss G: 1.5175\n",
      "Epoch [480/2000], Loss D: 0.6369, Loss G: 1.4584\n",
      "Epoch [481/2000], Loss D: 0.4533, Loss G: 1.8736\n",
      "Epoch [482/2000], Loss D: 0.7142, Loss G: 1.5167\n",
      "Epoch [483/2000], Loss D: 1.0996, Loss G: 1.1820\n",
      "Epoch [484/2000], Loss D: 1.2627, Loss G: 0.8252\n",
      "Epoch [485/2000], Loss D: 1.3105, Loss G: 0.9923\n",
      "Epoch [486/2000], Loss D: 1.4737, Loss G: 0.6659\n",
      "Epoch [487/2000], Loss D: 1.7219, Loss G: 0.7257\n",
      "Epoch [488/2000], Loss D: 1.8047, Loss G: 0.5515\n",
      "Epoch [489/2000], Loss D: 1.7785, Loss G: 0.8383\n",
      "Epoch [490/2000], Loss D: 1.7460, Loss G: 0.4938\n",
      "Epoch [491/2000], Loss D: 1.8712, Loss G: 0.6578\n",
      "Epoch [492/2000], Loss D: 1.9214, Loss G: 0.5689\n",
      "Epoch [493/2000], Loss D: 1.8885, Loss G: 0.4680\n",
      "Epoch [494/2000], Loss D: 2.0180, Loss G: 0.8203\n",
      "Epoch [495/2000], Loss D: 2.0224, Loss G: 1.3098\n",
      "Epoch [496/2000], Loss D: 1.6240, Loss G: 1.0307\n",
      "Epoch [497/2000], Loss D: 2.1345, Loss G: 0.5921\n",
      "Epoch [498/2000], Loss D: 2.1113, Loss G: 0.5049\n",
      "Epoch [499/2000], Loss D: 1.9647, Loss G: 0.6205\n",
      "Epoch [500/2000], Loss D: 1.8616, Loss G: 0.5355\n",
      "Epoch [501/2000], Loss D: 1.6722, Loss G: 0.6531\n",
      "Epoch [502/2000], Loss D: 1.5550, Loss G: 0.7265\n",
      "Epoch [503/2000], Loss D: 1.5300, Loss G: 0.6696\n",
      "Epoch [504/2000], Loss D: 1.3642, Loss G: 0.7754\n",
      "Epoch [505/2000], Loss D: 1.4089, Loss G: 0.7483\n",
      "Epoch [506/2000], Loss D: 1.5247, Loss G: 0.7841\n",
      "Epoch [507/2000], Loss D: 1.5835, Loss G: 0.6562\n",
      "Epoch [508/2000], Loss D: 1.6038, Loss G: 0.6808\n",
      "Epoch [509/2000], Loss D: 1.5011, Loss G: 0.9342\n",
      "Epoch [510/2000], Loss D: 1.5220, Loss G: 0.6855\n",
      "Epoch [511/2000], Loss D: 1.3906, Loss G: 0.8265\n",
      "Epoch [512/2000], Loss D: 1.0742, Loss G: 1.0612\n",
      "Epoch [513/2000], Loss D: 0.9303, Loss G: 1.6687\n",
      "Epoch [514/2000], Loss D: 1.2140, Loss G: 1.5977\n",
      "Epoch [515/2000], Loss D: 1.8215, Loss G: 1.2071\n",
      "Epoch [516/2000], Loss D: 1.7418, Loss G: 0.4623\n",
      "Epoch [517/2000], Loss D: 1.4428, Loss G: 0.8057\n",
      "Epoch [518/2000], Loss D: 1.1507, Loss G: 1.1780\n",
      "Epoch [519/2000], Loss D: 1.0183, Loss G: 1.4116\n",
      "Epoch [520/2000], Loss D: 1.1598, Loss G: 1.3302\n",
      "Epoch [521/2000], Loss D: 1.4576, Loss G: 1.2547\n",
      "Epoch [522/2000], Loss D: 1.5276, Loss G: 0.8745\n",
      "Epoch [523/2000], Loss D: 1.4714, Loss G: 0.8151\n",
      "Epoch [524/2000], Loss D: 1.2888, Loss G: 1.2021\n",
      "Epoch [525/2000], Loss D: 1.7589, Loss G: 1.5268\n",
      "Epoch [526/2000], Loss D: 1.3930, Loss G: 1.3366\n",
      "Epoch [527/2000], Loss D: 1.7613, Loss G: 2.0885\n",
      "Epoch [528/2000], Loss D: 1.1605, Loss G: 1.9657\n",
      "Epoch [529/2000], Loss D: 0.9683, Loss G: 1.2160\n",
      "Epoch [530/2000], Loss D: 1.2185, Loss G: 1.1853\n",
      "Epoch [531/2000], Loss D: 1.4683, Loss G: 1.3176\n",
      "Epoch [532/2000], Loss D: 1.9258, Loss G: 1.6972\n",
      "Epoch [533/2000], Loss D: 2.8407, Loss G: 1.0569\n",
      "Epoch [534/2000], Loss D: 1.9717, Loss G: 1.2663\n",
      "Epoch [535/2000], Loss D: 1.4846, Loss G: 1.3215\n",
      "Epoch [536/2000], Loss D: 0.8267, Loss G: 1.1218\n",
      "Epoch [537/2000], Loss D: 0.5739, Loss G: 2.2479\n",
      "Epoch [538/2000], Loss D: 0.6567, Loss G: 1.2960\n",
      "Epoch [539/2000], Loss D: 0.6682, Loss G: 1.8964\n",
      "Epoch [540/2000], Loss D: 1.1992, Loss G: 1.1420\n",
      "Epoch [541/2000], Loss D: 1.5563, Loss G: 0.6633\n",
      "Epoch [542/2000], Loss D: 1.4483, Loss G: 0.6942\n",
      "Epoch [543/2000], Loss D: 1.2145, Loss G: 0.9575\n",
      "Epoch [544/2000], Loss D: 1.0593, Loss G: 1.2098\n",
      "Epoch [545/2000], Loss D: 1.0671, Loss G: 1.2392\n",
      "Epoch [546/2000], Loss D: 1.2273, Loss G: 1.0737\n",
      "Epoch [547/2000], Loss D: 1.2031, Loss G: 1.1302\n",
      "Epoch [548/2000], Loss D: 1.1151, Loss G: 0.8003\n",
      "Epoch [549/2000], Loss D: 1.0974, Loss G: 1.0519\n",
      "Epoch [550/2000], Loss D: 1.0543, Loss G: 1.1701\n",
      "Epoch [551/2000], Loss D: 1.1302, Loss G: 1.0174\n",
      "Epoch [552/2000], Loss D: 1.1847, Loss G: 0.9789\n",
      "Epoch [553/2000], Loss D: 1.1126, Loss G: 0.9785\n",
      "Epoch [554/2000], Loss D: 1.3987, Loss G: 1.0140\n",
      "Epoch [555/2000], Loss D: 1.5595, Loss G: 0.7854\n",
      "Epoch [556/2000], Loss D: 1.8486, Loss G: 0.6351\n",
      "Epoch [557/2000], Loss D: 1.9045, Loss G: 0.7827\n",
      "Epoch [558/2000], Loss D: 1.6334, Loss G: 0.7432\n",
      "Epoch [559/2000], Loss D: 0.6547, Loss G: 1.3481\n",
      "Epoch [560/2000], Loss D: 0.7317, Loss G: 1.4894\n",
      "Epoch [561/2000], Loss D: 0.9232, Loss G: 2.2343\n",
      "Epoch [562/2000], Loss D: 2.1253, Loss G: 0.6791\n",
      "Epoch [563/2000], Loss D: 1.9817, Loss G: 1.8928\n",
      "Epoch [564/2000], Loss D: 1.7614, Loss G: 2.1595\n",
      "Epoch [565/2000], Loss D: 2.2706, Loss G: 1.6255\n",
      "Epoch [566/2000], Loss D: 1.6639, Loss G: 0.5450\n",
      "Epoch [567/2000], Loss D: 2.1840, Loss G: 0.9014\n",
      "Epoch [568/2000], Loss D: 1.8325, Loss G: 0.9413\n",
      "Epoch [569/2000], Loss D: 0.8787, Loss G: 1.4546\n",
      "Epoch [570/2000], Loss D: 1.1046, Loss G: 2.2175\n",
      "Epoch [571/2000], Loss D: 1.7177, Loss G: 0.9639\n",
      "Epoch [572/2000], Loss D: 2.0954, Loss G: 0.4803\n",
      "Epoch [573/2000], Loss D: 2.3426, Loss G: 0.5102\n",
      "Epoch [574/2000], Loss D: 2.2457, Loss G: 0.6333\n",
      "Epoch [575/2000], Loss D: 3.0389, Loss G: 0.2682\n",
      "Epoch [576/2000], Loss D: 2.2239, Loss G: 3.4233\n",
      "Epoch [577/2000], Loss D: 0.4466, Loss G: 1.5542\n",
      "Epoch [578/2000], Loss D: 0.2916, Loss G: 4.2997\n",
      "Epoch [579/2000], Loss D: 0.4488, Loss G: 7.3693\n",
      "Epoch [580/2000], Loss D: 0.6981, Loss G: 8.1911\n",
      "Epoch [581/2000], Loss D: 1.3561, Loss G: 7.8822\n",
      "Epoch [582/2000], Loss D: 2.2158, Loss G: 2.1690\n",
      "Epoch [583/2000], Loss D: 2.3232, Loss G: 3.2478\n",
      "Epoch [584/2000], Loss D: 2.6766, Loss G: 0.8523\n",
      "Epoch [585/2000], Loss D: 0.6587, Loss G: 7.0866\n",
      "Epoch [586/2000], Loss D: 1.2112, Loss G: 2.3861\n",
      "Epoch [587/2000], Loss D: 1.5388, Loss G: 1.4248\n",
      "Epoch [588/2000], Loss D: 1.4709, Loss G: 0.6760\n",
      "Epoch [589/2000], Loss D: 1.4047, Loss G: 0.9016\n",
      "Epoch [590/2000], Loss D: 1.2951, Loss G: 1.0294\n",
      "Epoch [591/2000], Loss D: 1.2917, Loss G: 0.7168\n",
      "Epoch [592/2000], Loss D: 1.3204, Loss G: 0.9542\n",
      "Epoch [593/2000], Loss D: 1.3539, Loss G: 0.7839\n",
      "Epoch [594/2000], Loss D: 1.3511, Loss G: 0.7847\n",
      "Epoch [595/2000], Loss D: 1.3028, Loss G: 0.8764\n",
      "Epoch [596/2000], Loss D: 1.2864, Loss G: 0.7534\n",
      "Epoch [597/2000], Loss D: 1.5801, Loss G: 0.7432\n",
      "Epoch [598/2000], Loss D: 1.6859, Loss G: 0.5829\n",
      "Epoch [599/2000], Loss D: 1.6805, Loss G: 0.6508\n",
      "Epoch [600/2000], Loss D: 1.7115, Loss G: 0.6261\n",
      "Epoch [601/2000], Loss D: 1.7257, Loss G: 0.5776\n",
      "Epoch [602/2000], Loss D: 1.7152, Loss G: 0.6127\n",
      "Epoch [603/2000], Loss D: 1.7043, Loss G: 0.6033\n",
      "Epoch [604/2000], Loss D: 1.6960, Loss G: 0.6074\n",
      "Epoch [605/2000], Loss D: 1.6350, Loss G: 0.6374\n",
      "Epoch [606/2000], Loss D: 1.5618, Loss G: 0.6767\n",
      "Epoch [607/2000], Loss D: 1.4698, Loss G: 0.7048\n",
      "Epoch [608/2000], Loss D: 1.4134, Loss G: 0.7685\n",
      "Epoch [609/2000], Loss D: 1.3559, Loss G: 1.0324\n",
      "Epoch [610/2000], Loss D: 1.3087, Loss G: 0.9146\n",
      "Epoch [611/2000], Loss D: 1.2038, Loss G: 1.0685\n",
      "Epoch [612/2000], Loss D: 1.4781, Loss G: 0.7998\n",
      "Epoch [613/2000], Loss D: 1.2080, Loss G: 0.9049\n",
      "Epoch [614/2000], Loss D: 1.0576, Loss G: 1.2548\n",
      "Epoch [615/2000], Loss D: 1.1687, Loss G: 1.0787\n",
      "Epoch [616/2000], Loss D: 1.5672, Loss G: 0.5942\n",
      "Epoch [617/2000], Loss D: 1.2803, Loss G: 1.6428\n",
      "Epoch [618/2000], Loss D: 0.4394, Loss G: 7.6895\n",
      "Epoch [619/2000], Loss D: 1.8785, Loss G: 3.1405\n",
      "Epoch [620/2000], Loss D: 2.8310, Loss G: 3.4653\n",
      "Epoch [621/2000], Loss D: 3.0052, Loss G: 0.3807\n",
      "Epoch [622/2000], Loss D: 2.0478, Loss G: 1.8292\n",
      "Epoch [623/2000], Loss D: 1.7739, Loss G: 0.6581\n",
      "Epoch [624/2000], Loss D: 1.5849, Loss G: 0.9592\n",
      "Epoch [625/2000], Loss D: 1.5161, Loss G: 0.9674\n",
      "Epoch [626/2000], Loss D: 1.4215, Loss G: 0.5789\n",
      "Epoch [627/2000], Loss D: 1.3251, Loss G: 0.9425\n",
      "Epoch [628/2000], Loss D: 1.3764, Loss G: 0.6962\n",
      "Epoch [629/2000], Loss D: 1.4179, Loss G: 0.7148\n",
      "Epoch [630/2000], Loss D: 1.4656, Loss G: 0.8043\n",
      "Epoch [631/2000], Loss D: 1.4381, Loss G: 0.6550\n",
      "Epoch [632/2000], Loss D: 1.3327, Loss G: 0.7611\n",
      "Epoch [633/2000], Loss D: 1.3118, Loss G: 0.7689\n",
      "Epoch [634/2000], Loss D: 1.2973, Loss G: 0.7793\n",
      "Epoch [635/2000], Loss D: 1.2253, Loss G: 0.8961\n",
      "Epoch [636/2000], Loss D: 1.3632, Loss G: 0.8045\n",
      "Epoch [637/2000], Loss D: 1.5185, Loss G: 0.7405\n",
      "Epoch [638/2000], Loss D: 1.4303, Loss G: 0.6475\n",
      "Epoch [639/2000], Loss D: 1.3426, Loss G: 0.8429\n",
      "Epoch [640/2000], Loss D: 1.4584, Loss G: 0.7286\n",
      "Epoch [641/2000], Loss D: 1.4477, Loss G: 0.7443\n",
      "Epoch [642/2000], Loss D: 1.4821, Loss G: 0.7823\n",
      "Epoch [643/2000], Loss D: 1.5541, Loss G: 0.7485\n",
      "Epoch [644/2000], Loss D: 1.5340, Loss G: 0.5553\n",
      "Epoch [645/2000], Loss D: 1.5508, Loss G: 0.7964\n",
      "Epoch [646/2000], Loss D: 1.5326, Loss G: 0.6065\n",
      "Epoch [647/2000], Loss D: 1.5122, Loss G: 0.6817\n",
      "Epoch [648/2000], Loss D: 1.4616, Loss G: 0.6760\n",
      "Epoch [649/2000], Loss D: 1.4428, Loss G: 0.6872\n",
      "Epoch [650/2000], Loss D: 1.4058, Loss G: 0.7275\n",
      "Epoch [651/2000], Loss D: 1.3828, Loss G: 0.7251\n",
      "Epoch [652/2000], Loss D: 1.3239, Loss G: 0.7825\n",
      "Epoch [653/2000], Loss D: 1.2910, Loss G: 0.8535\n",
      "Epoch [654/2000], Loss D: 1.2076, Loss G: 0.9048\n",
      "Epoch [655/2000], Loss D: 1.1917, Loss G: 0.8913\n",
      "Epoch [656/2000], Loss D: 1.1613, Loss G: 0.8861\n",
      "Epoch [657/2000], Loss D: 1.0957, Loss G: 0.9712\n",
      "Epoch [658/2000], Loss D: 1.0979, Loss G: 0.9533\n",
      "Epoch [659/2000], Loss D: 1.1003, Loss G: 0.9493\n",
      "Epoch [660/2000], Loss D: 1.1186, Loss G: 0.9303\n",
      "Epoch [661/2000], Loss D: 1.1471, Loss G: 0.9193\n",
      "Epoch [662/2000], Loss D: 1.2105, Loss G: 0.8707\n",
      "Epoch [663/2000], Loss D: 1.2609, Loss G: 0.8032\n",
      "Epoch [664/2000], Loss D: 1.2962, Loss G: 0.7639\n",
      "Epoch [665/2000], Loss D: 1.3331, Loss G: 0.7307\n",
      "Epoch [666/2000], Loss D: 1.3637, Loss G: 0.7320\n",
      "Epoch [667/2000], Loss D: 1.3982, Loss G: 0.6985\n",
      "Epoch [668/2000], Loss D: 1.4329, Loss G: 0.6909\n",
      "Epoch [669/2000], Loss D: 1.4746, Loss G: 0.6644\n",
      "Epoch [670/2000], Loss D: 1.4845, Loss G: 0.6704\n",
      "Epoch [671/2000], Loss D: 1.3055, Loss G: 0.8800\n",
      "Epoch [672/2000], Loss D: 1.1325, Loss G: 1.2860\n",
      "Epoch [673/2000], Loss D: 1.8021, Loss G: 0.4377\n",
      "Epoch [674/2000], Loss D: 1.5832, Loss G: 1.0081\n",
      "Epoch [675/2000], Loss D: 1.7030, Loss G: 0.6527\n",
      "Epoch [676/2000], Loss D: 1.9828, Loss G: 0.9283\n",
      "Epoch [677/2000], Loss D: 1.5412, Loss G: 0.6387\n",
      "Epoch [678/2000], Loss D: 1.5594, Loss G: 0.6107\n",
      "Epoch [679/2000], Loss D: 1.5069, Loss G: 0.7439\n",
      "Epoch [680/2000], Loss D: 1.5237, Loss G: 0.6146\n",
      "Epoch [681/2000], Loss D: 1.5317, Loss G: 0.6279\n",
      "Epoch [682/2000], Loss D: 1.5036, Loss G: 0.6873\n",
      "Epoch [683/2000], Loss D: 1.5124, Loss G: 0.6226\n",
      "Epoch [684/2000], Loss D: 1.5090, Loss G: 0.6440\n",
      "Epoch [685/2000], Loss D: 1.4896, Loss G: 0.6618\n",
      "Epoch [686/2000], Loss D: 1.4938, Loss G: 0.6462\n",
      "Epoch [687/2000], Loss D: 1.4824, Loss G: 0.6522\n",
      "Epoch [688/2000], Loss D: 1.4652, Loss G: 0.6652\n",
      "Epoch [689/2000], Loss D: 1.4618, Loss G: 0.6678\n",
      "Epoch [690/2000], Loss D: 1.4567, Loss G: 0.6629\n",
      "Epoch [691/2000], Loss D: 1.4401, Loss G: 0.6747\n",
      "Epoch [692/2000], Loss D: 1.4375, Loss G: 0.6772\n",
      "Epoch [693/2000], Loss D: 1.4241, Loss G: 0.6802\n",
      "Epoch [694/2000], Loss D: 1.4205, Loss G: 0.6905\n",
      "Epoch [695/2000], Loss D: 1.4104, Loss G: 0.6877\n",
      "Epoch [696/2000], Loss D: 1.3927, Loss G: 0.7005\n",
      "Epoch [697/2000], Loss D: 1.3629, Loss G: 0.7203\n",
      "Epoch [698/2000], Loss D: 1.3035, Loss G: 0.7447\n",
      "Epoch [699/2000], Loss D: 1.2578, Loss G: 0.7692\n",
      "Epoch [700/2000], Loss D: 1.2458, Loss G: 0.7944\n",
      "Epoch [701/2000], Loss D: 1.2364, Loss G: 0.7853\n",
      "Epoch [702/2000], Loss D: 1.2674, Loss G: 0.7701\n",
      "Epoch [703/2000], Loss D: 1.3000, Loss G: 0.7647\n",
      "Epoch [704/2000], Loss D: 1.3525, Loss G: 0.7290\n",
      "Epoch [705/2000], Loss D: 1.4047, Loss G: 0.6959\n",
      "Epoch [706/2000], Loss D: 1.4298, Loss G: 0.6901\n",
      "Epoch [707/2000], Loss D: 1.4587, Loss G: 0.6758\n",
      "Epoch [708/2000], Loss D: 1.4857, Loss G: 0.6522\n",
      "Epoch [709/2000], Loss D: 1.5188, Loss G: 0.6547\n",
      "Epoch [710/2000], Loss D: 1.5692, Loss G: 0.6299\n",
      "Epoch [711/2000], Loss D: 1.5860, Loss G: 0.6107\n",
      "Epoch [712/2000], Loss D: 1.5984, Loss G: 0.6064\n",
      "Epoch [713/2000], Loss D: 1.5860, Loss G: 0.6159\n",
      "Epoch [714/2000], Loss D: 1.5627, Loss G: 0.6198\n",
      "Epoch [715/2000], Loss D: 1.5335, Loss G: 0.6319\n",
      "Epoch [716/2000], Loss D: 1.4784, Loss G: 0.6583\n",
      "Epoch [717/2000], Loss D: 1.4054, Loss G: 0.6950\n",
      "Epoch [718/2000], Loss D: 1.2975, Loss G: 0.7515\n",
      "Epoch [719/2000], Loss D: 1.2745, Loss G: 0.7517\n",
      "Epoch [720/2000], Loss D: 1.2384, Loss G: 0.7819\n",
      "Epoch [721/2000], Loss D: 1.3426, Loss G: 0.6838\n",
      "Epoch [722/2000], Loss D: 1.3494, Loss G: 1.2243\n",
      "Epoch [723/2000], Loss D: 1.2315, Loss G: 0.9092\n",
      "Epoch [724/2000], Loss D: 1.2330, Loss G: 0.8546\n",
      "Epoch [725/2000], Loss D: 1.2733, Loss G: 0.9966\n",
      "Epoch [726/2000], Loss D: 1.4871, Loss G: 0.9349\n",
      "Epoch [727/2000], Loss D: 1.7542, Loss G: 0.6331\n",
      "Epoch [728/2000], Loss D: 1.8572, Loss G: 0.5353\n",
      "Epoch [729/2000], Loss D: 1.7573, Loss G: 0.6025\n",
      "Epoch [730/2000], Loss D: 1.5995, Loss G: 0.6620\n",
      "Epoch [731/2000], Loss D: 1.4728, Loss G: 0.6502\n",
      "Epoch [732/2000], Loss D: 1.3847, Loss G: 0.7146\n",
      "Epoch [733/2000], Loss D: 1.3368, Loss G: 0.7451\n",
      "Epoch [734/2000], Loss D: 1.3056, Loss G: 0.7508\n",
      "Epoch [735/2000], Loss D: 1.2845, Loss G: 0.7718\n",
      "Epoch [736/2000], Loss D: 1.2611, Loss G: 0.7701\n",
      "Epoch [737/2000], Loss D: 1.2843, Loss G: 0.7842\n",
      "Epoch [738/2000], Loss D: 1.2880, Loss G: 0.7570\n",
      "Epoch [739/2000], Loss D: 1.3313, Loss G: 0.7429\n",
      "Epoch [740/2000], Loss D: 1.3563, Loss G: 0.7438\n",
      "Epoch [741/2000], Loss D: 1.3623, Loss G: 0.7322\n",
      "Epoch [742/2000], Loss D: 1.3474, Loss G: 0.7324\n",
      "Epoch [743/2000], Loss D: 1.3229, Loss G: 0.7733\n",
      "Epoch [744/2000], Loss D: 1.2655, Loss G: 0.7883\n",
      "Epoch [745/2000], Loss D: 1.2474, Loss G: 0.8214\n",
      "Epoch [746/2000], Loss D: 1.2360, Loss G: 0.8189\n",
      "Epoch [747/2000], Loss D: 1.2737, Loss G: 0.7116\n",
      "Epoch [748/2000], Loss D: 1.2468, Loss G: 1.2587\n",
      "Epoch [749/2000], Loss D: 1.6850, Loss G: 0.7363\n",
      "Epoch [750/2000], Loss D: 1.5717, Loss G: 1.2350\n",
      "Epoch [751/2000], Loss D: 1.4600, Loss G: 0.6938\n",
      "Epoch [752/2000], Loss D: 1.4604, Loss G: 0.6677\n",
      "Epoch [753/2000], Loss D: 1.4608, Loss G: 0.8487\n",
      "Epoch [754/2000], Loss D: 1.4418, Loss G: 0.6972\n",
      "Epoch [755/2000], Loss D: 1.4176, Loss G: 0.6444\n",
      "Epoch [756/2000], Loss D: 1.3925, Loss G: 0.7434\n",
      "Epoch [757/2000], Loss D: 1.3567, Loss G: 0.7468\n",
      "Epoch [758/2000], Loss D: 1.3095, Loss G: 0.7026\n",
      "Epoch [759/2000], Loss D: 1.2881, Loss G: 0.7788\n",
      "Epoch [760/2000], Loss D: 1.2628, Loss G: 0.8485\n",
      "Epoch [761/2000], Loss D: 1.2417, Loss G: 0.8539\n",
      "Epoch [762/2000], Loss D: 1.3345, Loss G: 0.9205\n",
      "Epoch [763/2000], Loss D: 1.7952, Loss G: 0.6210\n",
      "Epoch [764/2000], Loss D: 1.7309, Loss G: 0.6301\n",
      "Epoch [765/2000], Loss D: 1.4876, Loss G: 0.7495\n",
      "Epoch [766/2000], Loss D: 1.2991, Loss G: 0.7476\n",
      "Epoch [767/2000], Loss D: 1.2354, Loss G: 0.7821\n",
      "Epoch [768/2000], Loss D: 1.2374, Loss G: 0.8222\n",
      "Epoch [769/2000], Loss D: 1.2340, Loss G: 0.7919\n",
      "Epoch [770/2000], Loss D: 1.2327, Loss G: 0.7803\n",
      "Epoch [771/2000], Loss D: 1.2442, Loss G: 0.7899\n",
      "Epoch [772/2000], Loss D: 1.2594, Loss G: 0.7770\n",
      "Epoch [773/2000], Loss D: 1.2833, Loss G: 0.7608\n",
      "Epoch [774/2000], Loss D: 1.3279, Loss G: 0.7416\n",
      "Epoch [775/2000], Loss D: 1.3794, Loss G: 0.7160\n",
      "Epoch [776/2000], Loss D: 1.4299, Loss G: 0.6871\n",
      "Epoch [777/2000], Loss D: 1.5169, Loss G: 0.6514\n",
      "Epoch [778/2000], Loss D: 1.5806, Loss G: 0.6247\n",
      "Epoch [779/2000], Loss D: 1.6508, Loss G: 0.5990\n",
      "Epoch [780/2000], Loss D: 1.6785, Loss G: 0.5722\n",
      "Epoch [781/2000], Loss D: 1.6997, Loss G: 0.5665\n",
      "Epoch [782/2000], Loss D: 1.6788, Loss G: 0.5821\n",
      "Epoch [783/2000], Loss D: 1.5954, Loss G: 0.6157\n",
      "Epoch [784/2000], Loss D: 1.4154, Loss G: 0.7096\n",
      "Epoch [785/2000], Loss D: 1.1853, Loss G: 0.8646\n",
      "Epoch [786/2000], Loss D: 1.0562, Loss G: 0.9440\n",
      "Epoch [787/2000], Loss D: 1.0685, Loss G: 0.8897\n",
      "Epoch [788/2000], Loss D: 1.3353, Loss G: 1.0639\n",
      "Epoch [789/2000], Loss D: 1.9396, Loss G: 0.7502\n",
      "Epoch [790/2000], Loss D: 1.6062, Loss G: 0.5838\n",
      "Epoch [791/2000], Loss D: 1.3117, Loss G: 0.8430\n",
      "Epoch [792/2000], Loss D: 1.2159, Loss G: 0.9718\n",
      "Epoch [793/2000], Loss D: 1.1383, Loss G: 0.9272\n",
      "Epoch [794/2000], Loss D: 1.0728, Loss G: 0.8412\n",
      "Epoch [795/2000], Loss D: 1.0335, Loss G: 0.9445\n",
      "Epoch [796/2000], Loss D: 1.0398, Loss G: 0.9961\n",
      "Epoch [797/2000], Loss D: 1.0398, Loss G: 0.9217\n",
      "Epoch [798/2000], Loss D: 1.0737, Loss G: 0.8989\n",
      "Epoch [799/2000], Loss D: 1.1022, Loss G: 0.9009\n",
      "Epoch [800/2000], Loss D: 1.1586, Loss G: 0.8812\n",
      "Epoch [801/2000], Loss D: 1.2261, Loss G: 0.7967\n",
      "Epoch [802/2000], Loss D: 1.3339, Loss G: 0.7598\n",
      "Epoch [803/2000], Loss D: 1.4082, Loss G: 0.7196\n",
      "Epoch [804/2000], Loss D: 1.5260, Loss G: 0.6655\n",
      "Epoch [805/2000], Loss D: 1.6181, Loss G: 0.6159\n",
      "Epoch [806/2000], Loss D: 1.6411, Loss G: 0.5905\n",
      "Epoch [807/2000], Loss D: 1.6784, Loss G: 0.5935\n",
      "Epoch [808/2000], Loss D: 1.6577, Loss G: 0.5896\n",
      "Epoch [809/2000], Loss D: 1.5868, Loss G: 0.6191\n",
      "Epoch [810/2000], Loss D: 1.4330, Loss G: 0.7137\n",
      "Epoch [811/2000], Loss D: 1.2103, Loss G: 0.9785\n",
      "Epoch [812/2000], Loss D: 1.1484, Loss G: 1.4182\n",
      "Epoch [813/2000], Loss D: 1.8795, Loss G: 0.6759\n",
      "Epoch [814/2000], Loss D: 1.6885, Loss G: 0.6835\n",
      "Epoch [815/2000], Loss D: 1.2175, Loss G: 1.0401\n",
      "Epoch [816/2000], Loss D: 0.9904, Loss G: 1.0529\n",
      "Epoch [817/2000], Loss D: 0.9157, Loss G: 0.9920\n",
      "Epoch [818/2000], Loss D: 0.8786, Loss G: 1.1105\n",
      "Epoch [819/2000], Loss D: 0.8743, Loss G: 1.1525\n",
      "Epoch [820/2000], Loss D: 0.8901, Loss G: 1.0541\n",
      "Epoch [821/2000], Loss D: 0.9324, Loss G: 1.0409\n",
      "Epoch [822/2000], Loss D: 1.0126, Loss G: 1.0189\n",
      "Epoch [823/2000], Loss D: 1.1101, Loss G: 0.9103\n",
      "Epoch [824/2000], Loss D: 1.2267, Loss G: 0.8372\n",
      "Epoch [825/2000], Loss D: 1.4063, Loss G: 0.7241\n",
      "Epoch [826/2000], Loss D: 1.6202, Loss G: 0.6126\n",
      "Epoch [827/2000], Loss D: 1.7989, Loss G: 0.5630\n",
      "Epoch [828/2000], Loss D: 1.9089, Loss G: 0.5115\n",
      "Epoch [829/2000], Loss D: 1.9199, Loss G: 0.4951\n",
      "Epoch [830/2000], Loss D: 1.8363, Loss G: 0.5310\n",
      "Epoch [831/2000], Loss D: 1.5582, Loss G: 0.6820\n",
      "Epoch [832/2000], Loss D: 1.1525, Loss G: 0.9975\n",
      "Epoch [833/2000], Loss D: 0.9969, Loss G: 1.2819\n",
      "Epoch [834/2000], Loss D: 1.5089, Loss G: 0.8412\n",
      "Epoch [835/2000], Loss D: 1.7196, Loss G: 0.6174\n",
      "Epoch [836/2000], Loss D: 1.5977, Loss G: 0.5981\n",
      "Epoch [837/2000], Loss D: 1.3583, Loss G: 0.7302\n",
      "Epoch [838/2000], Loss D: 1.1153, Loss G: 0.9168\n",
      "Epoch [839/2000], Loss D: 1.0341, Loss G: 0.9637\n",
      "Epoch [840/2000], Loss D: 1.0186, Loss G: 0.9298\n",
      "Epoch [841/2000], Loss D: 1.0583, Loss G: 0.9629\n",
      "Epoch [842/2000], Loss D: 1.2012, Loss G: 1.0795\n",
      "Epoch [843/2000], Loss D: 1.0740, Loss G: 0.8546\n",
      "Epoch [844/2000], Loss D: 1.1344, Loss G: 0.9221\n",
      "Epoch [845/2000], Loss D: 1.2386, Loss G: 0.8580\n",
      "Epoch [846/2000], Loss D: 1.3396, Loss G: 0.8296\n",
      "Epoch [847/2000], Loss D: 1.5449, Loss G: 0.7477\n",
      "Epoch [848/2000], Loss D: 1.7132, Loss G: 0.7200\n",
      "Epoch [849/2000], Loss D: 1.8249, Loss G: 0.5568\n",
      "Epoch [850/2000], Loss D: 1.8296, Loss G: 0.5798\n",
      "Epoch [851/2000], Loss D: 1.7491, Loss G: 0.6275\n",
      "Epoch [852/2000], Loss D: 1.6339, Loss G: 0.6586\n",
      "Epoch [853/2000], Loss D: 1.3970, Loss G: 0.7420\n",
      "Epoch [854/2000], Loss D: 1.0429, Loss G: 0.9680\n",
      "Epoch [855/2000], Loss D: 0.8080, Loss G: 1.1923\n",
      "Epoch [856/2000], Loss D: 0.9800, Loss G: 1.0986\n",
      "Epoch [857/2000], Loss D: 1.1377, Loss G: 1.0256\n",
      "Epoch [858/2000], Loss D: 1.6858, Loss G: 0.6776\n",
      "Epoch [859/2000], Loss D: 1.9675, Loss G: 0.6885\n",
      "Epoch [860/2000], Loss D: 1.9364, Loss G: 0.7741\n",
      "Epoch [861/2000], Loss D: 1.4119, Loss G: 0.9147\n",
      "Epoch [862/2000], Loss D: 1.1804, Loss G: 0.7940\n",
      "Epoch [863/2000], Loss D: 1.0573, Loss G: 0.9828\n",
      "Epoch [864/2000], Loss D: 0.9624, Loss G: 1.0915\n",
      "Epoch [865/2000], Loss D: 0.9552, Loss G: 1.0162\n",
      "Epoch [866/2000], Loss D: 0.9843, Loss G: 0.9525\n",
      "Epoch [867/2000], Loss D: 1.0111, Loss G: 0.9721\n",
      "Epoch [868/2000], Loss D: 1.0644, Loss G: 0.9308\n",
      "Epoch [869/2000], Loss D: 1.1566, Loss G: 0.8653\n",
      "Epoch [870/2000], Loss D: 1.3001, Loss G: 0.7788\n",
      "Epoch [871/2000], Loss D: 1.4684, Loss G: 0.6836\n",
      "Epoch [872/2000], Loss D: 1.6034, Loss G: 0.6290\n",
      "Epoch [873/2000], Loss D: 1.7334, Loss G: 0.7745\n",
      "Epoch [874/2000], Loss D: 1.7978, Loss G: 0.6005\n",
      "Epoch [875/2000], Loss D: 1.7097, Loss G: 0.6521\n",
      "Epoch [876/2000], Loss D: 1.2597, Loss G: 0.8474\n",
      "Epoch [877/2000], Loss D: 2.0230, Loss G: 1.8214\n",
      "Epoch [878/2000], Loss D: 1.1049, Loss G: 1.0852\n",
      "Epoch [879/2000], Loss D: 0.9730, Loss G: 1.7570\n",
      "Epoch [880/2000], Loss D: 1.4077, Loss G: 1.8926\n",
      "Epoch [881/2000], Loss D: 2.5956, Loss G: 0.7889\n",
      "Epoch [882/2000], Loss D: 1.2854, Loss G: 0.9030\n",
      "Epoch [883/2000], Loss D: 1.2281, Loss G: 0.8312\n",
      "Epoch [884/2000], Loss D: 1.1411, Loss G: 1.0362\n",
      "Epoch [885/2000], Loss D: 0.9632, Loss G: 1.1440\n",
      "Epoch [886/2000], Loss D: 0.7466, Loss G: 1.4653\n",
      "Epoch [887/2000], Loss D: 0.9656, Loss G: 1.5434\n",
      "Epoch [888/2000], Loss D: 2.5900, Loss G: 1.3345\n",
      "Epoch [889/2000], Loss D: 1.9216, Loss G: 0.6630\n",
      "Epoch [890/2000], Loss D: 1.6714, Loss G: 0.7056\n",
      "Epoch [891/2000], Loss D: 1.6041, Loss G: 0.9231\n",
      "Epoch [892/2000], Loss D: 1.5516, Loss G: 0.8593\n",
      "Epoch [893/2000], Loss D: 1.4542, Loss G: 1.6872\n",
      "Epoch [894/2000], Loss D: 2.7462, Loss G: 1.5098\n",
      "Epoch [895/2000], Loss D: 2.5965, Loss G: 0.7340\n",
      "Epoch [896/2000], Loss D: 1.6075, Loss G: 1.4898\n",
      "Epoch [897/2000], Loss D: 1.2067, Loss G: 0.9966\n",
      "Epoch [898/2000], Loss D: 0.8367, Loss G: 1.6402\n",
      "Epoch [899/2000], Loss D: 0.3846, Loss G: 3.0944\n",
      "Epoch [900/2000], Loss D: 0.5320, Loss G: 3.6497\n",
      "Epoch [901/2000], Loss D: 1.1870, Loss G: 2.8957\n",
      "Epoch [902/2000], Loss D: 1.3352, Loss G: 1.9012\n",
      "Epoch [903/2000], Loss D: 1.2450, Loss G: 0.7970\n",
      "Epoch [904/2000], Loss D: 1.0550, Loss G: 0.9395\n",
      "Epoch [905/2000], Loss D: 0.9203, Loss G: 1.1499\n",
      "Epoch [906/2000], Loss D: 0.8303, Loss G: 1.1813\n",
      "Epoch [907/2000], Loss D: 0.8502, Loss G: 1.1606\n",
      "Epoch [908/2000], Loss D: 0.9011, Loss G: 1.1396\n",
      "Epoch [909/2000], Loss D: 1.0663, Loss G: 1.0039\n",
      "Epoch [910/2000], Loss D: 1.3740, Loss G: 0.7617\n",
      "Epoch [911/2000], Loss D: 1.7684, Loss G: 0.6166\n",
      "Epoch [912/2000], Loss D: 2.1013, Loss G: 0.6112\n",
      "Epoch [913/2000], Loss D: 2.3402, Loss G: 0.8056\n",
      "Epoch [914/2000], Loss D: 2.5529, Loss G: 1.1620\n",
      "Epoch [915/2000], Loss D: 2.3898, Loss G: 0.3103\n",
      "Epoch [916/2000], Loss D: 2.1772, Loss G: 0.7284\n",
      "Epoch [917/2000], Loss D: 2.1054, Loss G: 0.6951\n",
      "Epoch [918/2000], Loss D: 1.7817, Loss G: 0.5878\n",
      "Epoch [919/2000], Loss D: 1.4275, Loss G: 1.2113\n",
      "Epoch [920/2000], Loss D: 1.4671, Loss G: 1.3063\n",
      "Epoch [921/2000], Loss D: 2.6466, Loss G: 0.9576\n",
      "Epoch [922/2000], Loss D: 2.5484, Loss G: 0.8810\n",
      "Epoch [923/2000], Loss D: 1.7961, Loss G: 0.9711\n",
      "Epoch [924/2000], Loss D: 1.7615, Loss G: 0.6827\n",
      "Epoch [925/2000], Loss D: 1.4587, Loss G: 0.6749\n",
      "Epoch [926/2000], Loss D: 1.1847, Loss G: 1.0044\n",
      "Epoch [927/2000], Loss D: 1.0208, Loss G: 1.0289\n",
      "Epoch [928/2000], Loss D: 0.9274, Loss G: 0.9865\n",
      "Epoch [929/2000], Loss D: 0.8383, Loss G: 1.1694\n",
      "Epoch [930/2000], Loss D: 0.8010, Loss G: 1.2100\n",
      "Epoch [931/2000], Loss D: 0.8122, Loss G: 1.1336\n",
      "Epoch [932/2000], Loss D: 0.8447, Loss G: 1.1732\n",
      "Epoch [933/2000], Loss D: 0.9495, Loss G: 1.0637\n",
      "Epoch [934/2000], Loss D: 1.0879, Loss G: 0.9206\n",
      "Epoch [935/2000], Loss D: 1.2707, Loss G: 0.8180\n",
      "Epoch [936/2000], Loss D: 1.4948, Loss G: 0.6943\n",
      "Epoch [937/2000], Loss D: 1.6983, Loss G: 0.5849\n",
      "Epoch [938/2000], Loss D: 1.8521, Loss G: 0.5243\n",
      "Epoch [939/2000], Loss D: 1.9057, Loss G: 0.5193\n",
      "Epoch [940/2000], Loss D: 1.8793, Loss G: 0.5184\n",
      "Epoch [941/2000], Loss D: 1.7701, Loss G: 0.5526\n",
      "Epoch [942/2000], Loss D: 1.5900, Loss G: 0.6393\n",
      "Epoch [943/2000], Loss D: 1.3206, Loss G: 0.8168\n",
      "Epoch [944/2000], Loss D: 0.9677, Loss G: 1.5160\n",
      "Epoch [945/2000], Loss D: 0.9498, Loss G: 3.2635\n",
      "Epoch [946/2000], Loss D: 1.9763, Loss G: 0.5524\n",
      "Epoch [947/2000], Loss D: 2.0503, Loss G: 1.5897\n",
      "Epoch [948/2000], Loss D: 2.0461, Loss G: 1.7177\n",
      "Epoch [949/2000], Loss D: 1.6002, Loss G: 2.0694\n",
      "Epoch [950/2000], Loss D: 1.6025, Loss G: 2.0353\n",
      "Epoch [951/2000], Loss D: 1.6266, Loss G: 1.3208\n",
      "Epoch [952/2000], Loss D: 1.3029, Loss G: 1.3072\n",
      "Epoch [953/2000], Loss D: 1.1685, Loss G: 1.6085\n",
      "Epoch [954/2000], Loss D: 1.3177, Loss G: 0.7127\n",
      "Epoch [955/2000], Loss D: 1.7603, Loss G: 0.7299\n",
      "Epoch [956/2000], Loss D: 2.1887, Loss G: 0.5990\n",
      "Epoch [957/2000], Loss D: 2.1866, Loss G: 0.4199\n",
      "Epoch [958/2000], Loss D: 1.6774, Loss G: 0.7091\n",
      "Epoch [959/2000], Loss D: 1.1896, Loss G: 1.1718\n",
      "Epoch [960/2000], Loss D: 0.8964, Loss G: 1.4296\n",
      "Epoch [961/2000], Loss D: 1.2446, Loss G: 0.9875\n",
      "Epoch [962/2000], Loss D: 1.6981, Loss G: 0.6424\n",
      "Epoch [963/2000], Loss D: 2.0320, Loss G: 0.4688\n",
      "Epoch [964/2000], Loss D: 1.9350, Loss G: 0.5124\n",
      "Epoch [965/2000], Loss D: 1.6587, Loss G: 0.6180\n",
      "Epoch [966/2000], Loss D: 1.4727, Loss G: 0.6733\n",
      "Epoch [967/2000], Loss D: 1.3192, Loss G: 0.7554\n",
      "Epoch [968/2000], Loss D: 1.1819, Loss G: 0.8492\n",
      "Epoch [969/2000], Loss D: 1.0708, Loss G: 0.9126\n",
      "Epoch [970/2000], Loss D: 0.9951, Loss G: 0.9778\n",
      "Epoch [971/2000], Loss D: 0.9583, Loss G: 1.0185\n",
      "Epoch [972/2000], Loss D: 0.9454, Loss G: 1.0452\n",
      "Epoch [973/2000], Loss D: 0.9995, Loss G: 1.0118\n",
      "Epoch [974/2000], Loss D: 1.1202, Loss G: 0.9218\n",
      "Epoch [975/2000], Loss D: 1.3326, Loss G: 0.7947\n",
      "Epoch [976/2000], Loss D: 1.6445, Loss G: 0.6499\n",
      "Epoch [977/2000], Loss D: 2.0391, Loss G: 0.5055\n",
      "Epoch [978/2000], Loss D: 2.2291, Loss G: 0.4417\n",
      "Epoch [979/2000], Loss D: 2.1935, Loss G: 0.4335\n",
      "Epoch [980/2000], Loss D: 1.9646, Loss G: 0.5061\n",
      "Epoch [981/2000], Loss D: 1.7051, Loss G: 0.5809\n",
      "Epoch [982/2000], Loss D: 1.4293, Loss G: 0.7261\n",
      "Epoch [983/2000], Loss D: 1.1325, Loss G: 0.9764\n",
      "Epoch [984/2000], Loss D: 0.9228, Loss G: 1.3000\n",
      "Epoch [985/2000], Loss D: 0.9543, Loss G: 1.3547\n",
      "Epoch [986/2000], Loss D: 1.4285, Loss G: 1.0683\n",
      "Epoch [987/2000], Loss D: 1.6036, Loss G: 1.1461\n",
      "Epoch [988/2000], Loss D: 1.4154, Loss G: 0.6760\n",
      "Epoch [989/2000], Loss D: 1.3287, Loss G: 0.7693\n",
      "Epoch [990/2000], Loss D: 1.2448, Loss G: 0.9814\n",
      "Epoch [991/2000], Loss D: 1.1815, Loss G: 0.8402\n",
      "Epoch [992/2000], Loss D: 1.1388, Loss G: 0.8191\n",
      "Epoch [993/2000], Loss D: 1.1143, Loss G: 0.9574\n",
      "Epoch [994/2000], Loss D: 1.1928, Loss G: 0.8863\n",
      "Epoch [995/2000], Loss D: 1.2524, Loss G: 0.7760\n",
      "Epoch [996/2000], Loss D: 1.3381, Loss G: 0.7914\n",
      "Epoch [997/2000], Loss D: 1.4842, Loss G: 0.7092\n",
      "Epoch [998/2000], Loss D: 1.5738, Loss G: 0.6270\n",
      "Epoch [999/2000], Loss D: 1.5421, Loss G: 0.6381\n",
      "Epoch [1000/2000], Loss D: 1.4975, Loss G: 0.6812\n",
      "Epoch [1001/2000], Loss D: 1.3923, Loss G: 0.7100\n",
      "Epoch [1002/2000], Loss D: 1.2955, Loss G: 0.7545\n",
      "Epoch [1003/2000], Loss D: 1.2041, Loss G: 0.8226\n",
      "Epoch [1004/2000], Loss D: 1.1469, Loss G: 0.8682\n",
      "Epoch [1005/2000], Loss D: 1.1255, Loss G: 0.8665\n",
      "Epoch [1006/2000], Loss D: 1.1627, Loss G: 0.8644\n",
      "Epoch [1007/2000], Loss D: 1.2238, Loss G: 0.8322\n",
      "Epoch [1008/2000], Loss D: 1.3511, Loss G: 0.7569\n",
      "Epoch [1009/2000], Loss D: 1.5190, Loss G: 0.6558\n",
      "Epoch [1010/2000], Loss D: 1.6668, Loss G: 0.5869\n",
      "Epoch [1011/2000], Loss D: 1.7476, Loss G: 0.5710\n",
      "Epoch [1012/2000], Loss D: 1.7322, Loss G: 0.5618\n",
      "Epoch [1013/2000], Loss D: 1.6792, Loss G: 0.5747\n",
      "Epoch [1014/2000], Loss D: 1.6094, Loss G: 0.6138\n",
      "Epoch [1015/2000], Loss D: 1.5472, Loss G: 0.6378\n",
      "Epoch [1016/2000], Loss D: 1.4761, Loss G: 0.6624\n",
      "Epoch [1017/2000], Loss D: 1.4070, Loss G: 0.6982\n",
      "Epoch [1018/2000], Loss D: 1.3523, Loss G: 0.7323\n",
      "Epoch [1019/2000], Loss D: 1.2935, Loss G: 0.7644\n",
      "Epoch [1020/2000], Loss D: 1.2771, Loss G: 0.7740\n",
      "Epoch [1021/2000], Loss D: 1.3061, Loss G: 0.7694\n",
      "Epoch [1022/2000], Loss D: 1.3343, Loss G: 0.7542\n",
      "Epoch [1023/2000], Loss D: 1.3418, Loss G: 0.7416\n",
      "Epoch [1024/2000], Loss D: 1.3498, Loss G: 0.7464\n",
      "Epoch [1025/2000], Loss D: 1.4076, Loss G: 0.7258\n",
      "Epoch [1026/2000], Loss D: 1.4748, Loss G: 0.6899\n",
      "Epoch [1027/2000], Loss D: 1.5387, Loss G: 0.6603\n",
      "Epoch [1028/2000], Loss D: 1.5714, Loss G: 0.6445\n",
      "Epoch [1029/2000], Loss D: 1.5487, Loss G: 0.6499\n",
      "Epoch [1030/2000], Loss D: 1.4654, Loss G: 0.6868\n",
      "Epoch [1031/2000], Loss D: 1.3546, Loss G: 0.7458\n",
      "Epoch [1032/2000], Loss D: 1.2752, Loss G: 0.7940\n",
      "Epoch [1033/2000], Loss D: 1.2234, Loss G: 0.8271\n",
      "Epoch [1034/2000], Loss D: 1.0867, Loss G: 0.9184\n",
      "Epoch [1035/2000], Loss D: 0.9990, Loss G: 1.0152\n",
      "Epoch [1036/2000], Loss D: 0.9841, Loss G: 1.0291\n",
      "Epoch [1037/2000], Loss D: 1.0221, Loss G: 0.9950\n",
      "Epoch [1038/2000], Loss D: 1.1353, Loss G: 0.9035\n",
      "Epoch [1039/2000], Loss D: 1.3158, Loss G: 0.7750\n",
      "Epoch [1040/2000], Loss D: 1.5087, Loss G: 0.6678\n",
      "Epoch [1041/2000], Loss D: 1.6030, Loss G: 0.6231\n",
      "Epoch [1042/2000], Loss D: 1.5845, Loss G: 0.6407\n",
      "Epoch [1043/2000], Loss D: 1.4978, Loss G: 0.6786\n",
      "Epoch [1044/2000], Loss D: 1.4403, Loss G: 0.6924\n",
      "Epoch [1045/2000], Loss D: 1.3571, Loss G: 0.7418\n",
      "Epoch [1046/2000], Loss D: 1.2919, Loss G: 0.7805\n",
      "Epoch [1047/2000], Loss D: 1.2375, Loss G: 0.8108\n",
      "Epoch [1048/2000], Loss D: 1.2300, Loss G: 0.8465\n",
      "Epoch [1049/2000], Loss D: 1.1494, Loss G: 0.8670\n",
      "Epoch [1050/2000], Loss D: 1.0473, Loss G: 0.9448\n",
      "Epoch [1051/2000], Loss D: 1.0236, Loss G: 0.9806\n",
      "Epoch [1052/2000], Loss D: 1.0901, Loss G: 0.9290\n",
      "Epoch [1053/2000], Loss D: 1.1968, Loss G: 0.8356\n",
      "Epoch [1054/2000], Loss D: 1.3131, Loss G: 0.7655\n",
      "Epoch [1055/2000], Loss D: 1.4280, Loss G: 0.6983\n",
      "Epoch [1056/2000], Loss D: 1.5489, Loss G: 0.6425\n",
      "Epoch [1057/2000], Loss D: 1.6712, Loss G: 0.5909\n",
      "Epoch [1058/2000], Loss D: 1.7366, Loss G: 0.5815\n",
      "Epoch [1059/2000], Loss D: 1.7003, Loss G: 0.5883\n",
      "Epoch [1060/2000], Loss D: 1.6154, Loss G: 0.6117\n",
      "Epoch [1061/2000], Loss D: 1.4777, Loss G: 0.6745\n",
      "Epoch [1062/2000], Loss D: 1.3098, Loss G: 0.7694\n",
      "Epoch [1063/2000], Loss D: 1.2075, Loss G: 0.8508\n",
      "Epoch [1064/2000], Loss D: 1.1457, Loss G: 0.8973\n",
      "Epoch [1065/2000], Loss D: 1.1430, Loss G: 0.8966\n",
      "Epoch [1066/2000], Loss D: 1.2181, Loss G: 0.8406\n",
      "Epoch [1067/2000], Loss D: 1.4186, Loss G: 0.7163\n",
      "Epoch [1068/2000], Loss D: 1.6155, Loss G: 0.6198\n",
      "Epoch [1069/2000], Loss D: 1.6913, Loss G: 0.5845\n",
      "Epoch [1070/2000], Loss D: 1.6472, Loss G: 0.6007\n",
      "Epoch [1071/2000], Loss D: 1.5733, Loss G: 0.6382\n",
      "Epoch [1072/2000], Loss D: 1.4726, Loss G: 0.6793\n",
      "Epoch [1073/2000], Loss D: 1.3440, Loss G: 0.7415\n",
      "Epoch [1074/2000], Loss D: 1.2724, Loss G: 0.7943\n",
      "Epoch [1075/2000], Loss D: 1.3302, Loss G: 0.7743\n",
      "Epoch [1076/2000], Loss D: 1.2818, Loss G: 0.7876\n",
      "Epoch [1077/2000], Loss D: 1.1660, Loss G: 0.8585\n",
      "Epoch [1078/2000], Loss D: 1.1463, Loss G: 0.8687\n",
      "Epoch [1079/2000], Loss D: 1.2063, Loss G: 0.8228\n",
      "Epoch [1080/2000], Loss D: 1.2474, Loss G: 0.8236\n",
      "Epoch [1081/2000], Loss D: 1.2146, Loss G: 0.8575\n",
      "Epoch [1082/2000], Loss D: 1.1497, Loss G: 0.8942\n",
      "Epoch [1083/2000], Loss D: 1.2304, Loss G: 0.8228\n",
      "Epoch [1084/2000], Loss D: 1.4021, Loss G: 0.7357\n",
      "Epoch [1085/2000], Loss D: 1.6616, Loss G: 0.6234\n",
      "Epoch [1086/2000], Loss D: 2.0205, Loss G: 0.5115\n",
      "Epoch [1087/2000], Loss D: 1.8091, Loss G: 0.5893\n",
      "Epoch [1088/2000], Loss D: 1.5739, Loss G: 0.6605\n",
      "Epoch [1089/2000], Loss D: 1.4277, Loss G: 0.7218\n",
      "Epoch [1090/2000], Loss D: 1.3088, Loss G: 0.7920\n",
      "Epoch [1091/2000], Loss D: 1.2539, Loss G: 0.7997\n",
      "Epoch [1092/2000], Loss D: 1.2106, Loss G: 0.8326\n",
      "Epoch [1093/2000], Loss D: 1.1837, Loss G: 0.8547\n",
      "Epoch [1094/2000], Loss D: 1.2007, Loss G: 0.8397\n",
      "Epoch [1095/2000], Loss D: 1.2517, Loss G: 0.8019\n",
      "Epoch [1096/2000], Loss D: 1.3038, Loss G: 0.7664\n",
      "Epoch [1097/2000], Loss D: 1.3124, Loss G: 0.7674\n",
      "Epoch [1098/2000], Loss D: 1.2522, Loss G: 0.8169\n",
      "Epoch [1099/2000], Loss D: 1.1904, Loss G: 0.8506\n",
      "Epoch [1100/2000], Loss D: 1.4586, Loss G: 0.7315\n",
      "Epoch [1101/2000], Loss D: 1.3728, Loss G: 0.6977\n",
      "Epoch [1102/2000], Loss D: 1.2709, Loss G: 0.7890\n",
      "Epoch [1103/2000], Loss D: 1.2437, Loss G: 0.8176\n",
      "Epoch [1104/2000], Loss D: 1.1645, Loss G: 0.8788\n",
      "Epoch [1105/2000], Loss D: 1.1324, Loss G: 0.8923\n",
      "Epoch [1106/2000], Loss D: 1.1271, Loss G: 0.8999\n",
      "Epoch [1107/2000], Loss D: 1.1967, Loss G: 0.8662\n",
      "Epoch [1108/2000], Loss D: 1.3357, Loss G: 0.7622\n",
      "Epoch [1109/2000], Loss D: 1.3657, Loss G: 0.7779\n",
      "Epoch [1110/2000], Loss D: 1.3900, Loss G: 0.7679\n",
      "Epoch [1111/2000], Loss D: 1.6008, Loss G: 0.6471\n",
      "Epoch [1112/2000], Loss D: 1.6589, Loss G: 0.6084\n",
      "Epoch [1113/2000], Loss D: 1.6515, Loss G: 0.6044\n",
      "Epoch [1114/2000], Loss D: 1.5407, Loss G: 0.6646\n",
      "Epoch [1115/2000], Loss D: 1.3604, Loss G: 0.7852\n",
      "Epoch [1116/2000], Loss D: 1.1479, Loss G: 1.0130\n",
      "Epoch [1117/2000], Loss D: 1.1412, Loss G: 1.0628\n",
      "Epoch [1118/2000], Loss D: 1.6050, Loss G: 0.6818\n",
      "Epoch [1119/2000], Loss D: 1.9457, Loss G: 0.5667\n",
      "Epoch [1120/2000], Loss D: 1.6851, Loss G: 0.6221\n",
      "Epoch [1121/2000], Loss D: 1.3867, Loss G: 0.7403\n",
      "Epoch [1122/2000], Loss D: 1.0938, Loss G: 0.9222\n",
      "Epoch [1123/2000], Loss D: 0.8273, Loss G: 1.1887\n",
      "Epoch [1124/2000], Loss D: 0.7137, Loss G: 1.3254\n",
      "Epoch [1125/2000], Loss D: 0.7895, Loss G: 1.1872\n",
      "Epoch [1126/2000], Loss D: 0.9393, Loss G: 1.0367\n",
      "Epoch [1127/2000], Loss D: 1.0866, Loss G: 0.9418\n",
      "Epoch [1128/2000], Loss D: 1.3272, Loss G: 0.8090\n",
      "Epoch [1129/2000], Loss D: 1.5780, Loss G: 0.6815\n",
      "Epoch [1130/2000], Loss D: 1.7429, Loss G: 0.5995\n",
      "Epoch [1131/2000], Loss D: 1.7421, Loss G: 0.5969\n",
      "Epoch [1132/2000], Loss D: 1.5777, Loss G: 0.6756\n",
      "Epoch [1133/2000], Loss D: 1.4713, Loss G: 0.7869\n",
      "Epoch [1134/2000], Loss D: 1.4568, Loss G: 0.7216\n",
      "Epoch [1135/2000], Loss D: 1.7623, Loss G: 1.1320\n",
      "Epoch [1136/2000], Loss D: 1.4168, Loss G: 0.8602\n",
      "Epoch [1137/2000], Loss D: 1.3562, Loss G: 0.9007\n",
      "Epoch [1138/2000], Loss D: 2.7881, Loss G: 2.9721\n",
      "Epoch [1139/2000], Loss D: 8.3743, Loss G: 0.4421\n",
      "Epoch [1140/2000], Loss D: 6.4145, Loss G: 0.0358\n",
      "Epoch [1141/2000], Loss D: 1.5491, Loss G: 4.4137\n",
      "Epoch [1142/2000], Loss D: 0.9278, Loss G: 2.1491\n",
      "Epoch [1143/2000], Loss D: 4.5488, Loss G: 1.0817\n",
      "Epoch [1144/2000], Loss D: 3.7925, Loss G: 0.9296\n",
      "Epoch [1145/2000], Loss D: 0.2946, Loss G: 5.7750\n",
      "Epoch [1146/2000], Loss D: 0.8645, Loss G: 2.8615\n",
      "Epoch [1147/2000], Loss D: 0.6919, Loss G: 3.8684\n",
      "Epoch [1148/2000], Loss D: 3.2908, Loss G: 2.6582\n",
      "Epoch [1149/2000], Loss D: 4.6424, Loss G: 0.0829\n",
      "Epoch [1150/2000], Loss D: 1.5910, Loss G: 1.4555\n",
      "Epoch [1151/2000], Loss D: 0.1070, Loss G: 5.0370\n",
      "Epoch [1152/2000], Loss D: 0.5840, Loss G: 5.3843\n",
      "Epoch [1153/2000], Loss D: 2.4348, Loss G: 1.4217\n",
      "Epoch [1154/2000], Loss D: 1.3712, Loss G: 1.1754\n",
      "Epoch [1155/2000], Loss D: 0.5070, Loss G: 1.4833\n",
      "Epoch [1156/2000], Loss D: 0.4344, Loss G: 1.9228\n",
      "Epoch [1157/2000], Loss D: 0.5513, Loss G: 2.1757\n",
      "Epoch [1158/2000], Loss D: 0.8503, Loss G: 1.9051\n",
      "Epoch [1159/2000], Loss D: 1.5180, Loss G: 2.5275\n",
      "Epoch [1160/2000], Loss D: 4.5161, Loss G: 3.4367\n",
      "Epoch [1161/2000], Loss D: 2.0647, Loss G: 1.4093\n",
      "Epoch [1162/2000], Loss D: 1.7338, Loss G: 0.6782\n",
      "Epoch [1163/2000], Loss D: 0.8128, Loss G: 1.7161\n",
      "Epoch [1164/2000], Loss D: 0.7240, Loss G: 2.5746\n",
      "Epoch [1165/2000], Loss D: 1.2347, Loss G: 1.6536\n",
      "Epoch [1166/2000], Loss D: 3.0776, Loss G: 1.1655\n",
      "Epoch [1167/2000], Loss D: 5.7007, Loss G: 0.4684\n",
      "Epoch [1168/2000], Loss D: 4.0328, Loss G: 0.3929\n",
      "Epoch [1169/2000], Loss D: 0.4729, Loss G: 3.2371\n",
      "Epoch [1170/2000], Loss D: 0.0870, Loss G: 6.2681\n",
      "Epoch [1171/2000], Loss D: 0.0025, Loss G: 8.0276\n",
      "Epoch [1172/2000], Loss D: 0.0456, Loss G: 8.7579\n",
      "Epoch [1173/2000], Loss D: 1.9158, Loss G: 5.6427\n",
      "Epoch [1174/2000], Loss D: 4.3622, Loss G: 2.0017\n",
      "Epoch [1175/2000], Loss D: 3.5829, Loss G: 1.1289\n",
      "Epoch [1176/2000], Loss D: 2.4734, Loss G: 1.1446\n",
      "Epoch [1177/2000], Loss D: 1.7040, Loss G: 0.6885\n",
      "Epoch [1178/2000], Loss D: 1.6985, Loss G: 0.5764\n",
      "Epoch [1179/2000], Loss D: 1.5242, Loss G: 0.8905\n",
      "Epoch [1180/2000], Loss D: 1.3438, Loss G: 0.9174\n",
      "Epoch [1181/2000], Loss D: 1.1303, Loss G: 1.1731\n",
      "Epoch [1182/2000], Loss D: 1.8412, Loss G: 0.8856\n",
      "Epoch [1183/2000], Loss D: 2.7171, Loss G: 0.7834\n",
      "Epoch [1184/2000], Loss D: 2.3009, Loss G: 0.6559\n",
      "Epoch [1185/2000], Loss D: 1.5554, Loss G: 0.9464\n",
      "Epoch [1186/2000], Loss D: 1.3621, Loss G: 0.7503\n",
      "Epoch [1187/2000], Loss D: 1.3095, Loss G: 0.7006\n",
      "Epoch [1188/2000], Loss D: 1.2056, Loss G: 0.9378\n",
      "Epoch [1189/2000], Loss D: 1.1149, Loss G: 0.9156\n",
      "Epoch [1190/2000], Loss D: 1.0349, Loss G: 0.8747\n",
      "Epoch [1191/2000], Loss D: 1.0268, Loss G: 0.9896\n",
      "Epoch [1192/2000], Loss D: 1.0493, Loss G: 0.9524\n",
      "Epoch [1193/2000], Loss D: 1.0777, Loss G: 0.8953\n",
      "Epoch [1194/2000], Loss D: 1.1625, Loss G: 0.8944\n",
      "Epoch [1195/2000], Loss D: 1.3135, Loss G: 0.7966\n",
      "Epoch [1196/2000], Loss D: 1.4349, Loss G: 0.7056\n",
      "Epoch [1197/2000], Loss D: 1.5327, Loss G: 0.6792\n",
      "Epoch [1198/2000], Loss D: 1.6644, Loss G: 0.6615\n",
      "Epoch [1199/2000], Loss D: 1.6157, Loss G: 0.6007\n",
      "Epoch [1200/2000], Loss D: 1.5805, Loss G: 0.6522\n",
      "Epoch [1201/2000], Loss D: 1.5601, Loss G: 0.7089\n",
      "Epoch [1202/2000], Loss D: 1.3958, Loss G: 0.9187\n",
      "Epoch [1203/2000], Loss D: 1.2870, Loss G: 0.8427\n",
      "Epoch [1204/2000], Loss D: 1.2367, Loss G: 0.8877\n",
      "Epoch [1205/2000], Loss D: 1.0910, Loss G: 0.9545\n",
      "Epoch [1206/2000], Loss D: 1.0122, Loss G: 0.9658\n",
      "Epoch [1207/2000], Loss D: 0.9692, Loss G: 1.0059\n",
      "Epoch [1208/2000], Loss D: 1.0142, Loss G: 0.9970\n",
      "Epoch [1209/2000], Loss D: 1.1961, Loss G: 0.8939\n",
      "Epoch [1210/2000], Loss D: 1.5674, Loss G: 0.6864\n",
      "Epoch [1211/2000], Loss D: 1.8855, Loss G: 0.5216\n",
      "Epoch [1212/2000], Loss D: 1.6644, Loss G: 0.6389\n",
      "Epoch [1213/2000], Loss D: 1.2168, Loss G: 0.8579\n",
      "Epoch [1214/2000], Loss D: 1.0087, Loss G: 0.9974\n",
      "Epoch [1215/2000], Loss D: 0.9579, Loss G: 0.9998\n",
      "Epoch [1216/2000], Loss D: 1.0035, Loss G: 0.9796\n",
      "Epoch [1217/2000], Loss D: 1.0450, Loss G: 0.9726\n",
      "Epoch [1218/2000], Loss D: 1.1003, Loss G: 0.8900\n",
      "Epoch [1219/2000], Loss D: 1.1144, Loss G: 0.8467\n",
      "Epoch [1220/2000], Loss D: 1.1646, Loss G: 0.8955\n",
      "Epoch [1221/2000], Loss D: 1.2819, Loss G: 0.8043\n",
      "Epoch [1222/2000], Loss D: 1.3621, Loss G: 0.7595\n",
      "Epoch [1223/2000], Loss D: 1.4773, Loss G: 0.6590\n",
      "Epoch [1224/2000], Loss D: 1.5657, Loss G: 0.7524\n",
      "Epoch [1225/2000], Loss D: 1.4993, Loss G: 0.6362\n",
      "Epoch [1226/2000], Loss D: 1.6049, Loss G: 0.6613\n",
      "Epoch [1227/2000], Loss D: 1.5052, Loss G: 0.6792\n",
      "Epoch [1228/2000], Loss D: 1.4771, Loss G: 0.7991\n",
      "Epoch [1229/2000], Loss D: 1.2728, Loss G: 0.8802\n",
      "Epoch [1230/2000], Loss D: 0.8734, Loss G: 1.2787\n",
      "Epoch [1231/2000], Loss D: 0.9968, Loss G: 1.2949\n",
      "Epoch [1232/2000], Loss D: 1.4018, Loss G: 0.8141\n",
      "Epoch [1233/2000], Loss D: 1.8962, Loss G: 0.5650\n",
      "Epoch [1234/2000], Loss D: 2.1235, Loss G: 0.5090\n",
      "Epoch [1235/2000], Loss D: 2.0464, Loss G: 0.4606\n",
      "Epoch [1236/2000], Loss D: 1.7141, Loss G: 0.6076\n",
      "Epoch [1237/2000], Loss D: 1.3958, Loss G: 0.7490\n",
      "Epoch [1238/2000], Loss D: 1.2109, Loss G: 0.7931\n",
      "Epoch [1239/2000], Loss D: 1.1218, Loss G: 0.8591\n",
      "Epoch [1240/2000], Loss D: 1.0189, Loss G: 0.9615\n",
      "Epoch [1241/2000], Loss D: 0.9528, Loss G: 0.9925\n",
      "Epoch [1242/2000], Loss D: 0.9199, Loss G: 1.0054\n",
      "Epoch [1243/2000], Loss D: 0.8896, Loss G: 1.0453\n",
      "Epoch [1244/2000], Loss D: 0.8783, Loss G: 1.0693\n",
      "Epoch [1245/2000], Loss D: 0.8877, Loss G: 1.0617\n",
      "Epoch [1246/2000], Loss D: 0.9185, Loss G: 1.0429\n",
      "Epoch [1247/2000], Loss D: 0.9523, Loss G: 1.0415\n",
      "Epoch [1248/2000], Loss D: 1.0838, Loss G: 0.9448\n",
      "Epoch [1249/2000], Loss D: 1.2155, Loss G: 0.8448\n",
      "Epoch [1250/2000], Loss D: 1.4561, Loss G: 0.7182\n",
      "Epoch [1251/2000], Loss D: 1.6707, Loss G: 0.6329\n",
      "Epoch [1252/2000], Loss D: 1.8669, Loss G: 0.5380\n",
      "Epoch [1253/2000], Loss D: 1.8848, Loss G: 0.5095\n",
      "Epoch [1254/2000], Loss D: 1.7101, Loss G: 0.5813\n",
      "Epoch [1255/2000], Loss D: 1.4087, Loss G: 0.8982\n",
      "Epoch [1256/2000], Loss D: 1.5788, Loss G: 3.9222\n",
      "Epoch [1257/2000], Loss D: 2.1096, Loss G: 1.4854\n",
      "Epoch [1258/2000], Loss D: 1.7119, Loss G: 0.6721\n",
      "Epoch [1259/2000], Loss D: 1.2368, Loss G: 1.9275\n",
      "Epoch [1260/2000], Loss D: 0.8403, Loss G: 1.1258\n",
      "Epoch [1261/2000], Loss D: 0.9405, Loss G: 1.4227\n",
      "Epoch [1262/2000], Loss D: 1.0572, Loss G: 1.7153\n",
      "Epoch [1263/2000], Loss D: 1.1100, Loss G: 1.5559\n",
      "Epoch [1264/2000], Loss D: 2.0999, Loss G: 1.2927\n",
      "Epoch [1265/2000], Loss D: 2.3695, Loss G: 0.6436\n",
      "Epoch [1266/2000], Loss D: 2.6875, Loss G: 0.5987\n",
      "Epoch [1267/2000], Loss D: 1.9129, Loss G: 1.1539\n",
      "Epoch [1268/2000], Loss D: 2.1838, Loss G: 0.6407\n",
      "Epoch [1269/2000], Loss D: 2.0292, Loss G: 0.3965\n",
      "Epoch [1270/2000], Loss D: 1.9416, Loss G: 0.6316\n",
      "Epoch [1271/2000], Loss D: 1.8173, Loss G: 0.6299\n",
      "Epoch [1272/2000], Loss D: 1.5855, Loss G: 0.5855\n",
      "Epoch [1273/2000], Loss D: 1.3080, Loss G: 0.8426\n",
      "Epoch [1274/2000], Loss D: 0.9167, Loss G: 1.6813\n",
      "Epoch [1275/2000], Loss D: 1.3433, Loss G: 0.9813\n",
      "Epoch [1276/2000], Loss D: 1.4783, Loss G: 0.5773\n",
      "Epoch [1277/2000], Loss D: 0.7233, Loss G: 1.6502\n",
      "Epoch [1278/2000], Loss D: 0.3759, Loss G: 2.4632\n",
      "Epoch [1279/2000], Loss D: 1.1427, Loss G: 2.8815\n",
      "Epoch [1280/2000], Loss D: 1.6010, Loss G: 2.0934\n",
      "Epoch [1281/2000], Loss D: 4.1133, Loss G: 0.2293\n",
      "Epoch [1282/2000], Loss D: 1.8383, Loss G: 3.9187\n",
      "Epoch [1283/2000], Loss D: 4.1003, Loss G: 0.7504\n",
      "Epoch [1284/2000], Loss D: 4.1114, Loss G: 1.3680\n",
      "Epoch [1285/2000], Loss D: 4.7816, Loss G: 0.1209\n",
      "Epoch [1286/2000], Loss D: 2.8299, Loss G: 3.4104\n",
      "Epoch [1287/2000], Loss D: 2.1102, Loss G: 0.4603\n",
      "Epoch [1288/2000], Loss D: 1.5639, Loss G: 1.9201\n",
      "Epoch [1289/2000], Loss D: 1.3008, Loss G: 1.1967\n",
      "Epoch [1290/2000], Loss D: 1.0238, Loss G: 1.0713\n",
      "Epoch [1291/2000], Loss D: 0.9760, Loss G: 1.5294\n",
      "Epoch [1292/2000], Loss D: 0.8521, Loss G: 0.9697\n",
      "Epoch [1293/2000], Loss D: 0.8681, Loss G: 1.2061\n",
      "Epoch [1294/2000], Loss D: 0.9217, Loss G: 1.1958\n",
      "Epoch [1295/2000], Loss D: 0.9514, Loss G: 0.9389\n",
      "Epoch [1296/2000], Loss D: 1.0324, Loss G: 0.9840\n",
      "Epoch [1297/2000], Loss D: 1.1439, Loss G: 0.9536\n",
      "Epoch [1298/2000], Loss D: 1.2272, Loss G: 0.8027\n",
      "Epoch [1299/2000], Loss D: 1.3337, Loss G: 0.7476\n",
      "Epoch [1300/2000], Loss D: 1.5458, Loss G: 0.7065\n",
      "Epoch [1301/2000], Loss D: 1.7735, Loss G: 0.5799\n",
      "Epoch [1302/2000], Loss D: 2.3380, Loss G: 0.4208\n",
      "Epoch [1303/2000], Loss D: 2.9283, Loss G: 0.3243\n",
      "Epoch [1304/2000], Loss D: 2.8117, Loss G: 0.3223\n",
      "Epoch [1305/2000], Loss D: 2.4355, Loss G: 0.3833\n",
      "Epoch [1306/2000], Loss D: 2.1515, Loss G: 0.4383\n",
      "Epoch [1307/2000], Loss D: 1.9409, Loss G: 0.4945\n",
      "Epoch [1308/2000], Loss D: 1.7763, Loss G: 0.5471\n",
      "Epoch [1309/2000], Loss D: 1.6534, Loss G: 0.5909\n",
      "Epoch [1310/2000], Loss D: 1.5418, Loss G: 0.6346\n",
      "Epoch [1311/2000], Loss D: 1.4498, Loss G: 0.6759\n",
      "Epoch [1312/2000], Loss D: 1.3758, Loss G: 0.7138\n",
      "Epoch [1313/2000], Loss D: 1.3082, Loss G: 0.7498\n",
      "Epoch [1314/2000], Loss D: 1.2548, Loss G: 0.7798\n",
      "Epoch [1315/2000], Loss D: 1.2041, Loss G: 0.8111\n",
      "Epoch [1316/2000], Loss D: 1.1688, Loss G: 0.8352\n",
      "Epoch [1317/2000], Loss D: 1.1335, Loss G: 0.8548\n",
      "Epoch [1318/2000], Loss D: 1.1011, Loss G: 0.8818\n",
      "Epoch [1319/2000], Loss D: 1.0708, Loss G: 0.9079\n",
      "Epoch [1320/2000], Loss D: 1.0405, Loss G: 0.9278\n",
      "Epoch [1321/2000], Loss D: 1.0251, Loss G: 0.9359\n",
      "Epoch [1322/2000], Loss D: 1.0628, Loss G: 0.9268\n",
      "Epoch [1323/2000], Loss D: 1.0618, Loss G: 0.9098\n",
      "Epoch [1324/2000], Loss D: 1.0438, Loss G: 0.9257\n",
      "Epoch [1325/2000], Loss D: 1.0288, Loss G: 0.9338\n",
      "Epoch [1326/2000], Loss D: 0.9960, Loss G: 0.9550\n",
      "Epoch [1327/2000], Loss D: 0.9632, Loss G: 0.9854\n",
      "Epoch [1328/2000], Loss D: 0.9226, Loss G: 1.0176\n",
      "Epoch [1329/2000], Loss D: 0.8826, Loss G: 1.0516\n",
      "Epoch [1330/2000], Loss D: 0.8360, Loss G: 1.1050\n",
      "Epoch [1331/2000], Loss D: 0.7895, Loss G: 1.1429\n",
      "Epoch [1332/2000], Loss D: 0.7410, Loss G: 1.1995\n",
      "Epoch [1333/2000], Loss D: 0.7022, Loss G: 1.2496\n",
      "Epoch [1334/2000], Loss D: 0.6663, Loss G: 1.2913\n",
      "Epoch [1335/2000], Loss D: 0.6537, Loss G: 1.3162\n",
      "Epoch [1336/2000], Loss D: 0.7831, Loss G: 1.2026\n",
      "Epoch [1337/2000], Loss D: 1.2705, Loss G: 0.8658\n",
      "Epoch [1338/2000], Loss D: 1.7375, Loss G: 0.5639\n",
      "Epoch [1339/2000], Loss D: 1.9657, Loss G: 0.4930\n",
      "Epoch [1340/2000], Loss D: 2.0450, Loss G: 0.4688\n",
      "Epoch [1341/2000], Loss D: 2.0284, Loss G: 0.4647\n",
      "Epoch [1342/2000], Loss D: 1.9605, Loss G: 0.4895\n",
      "Epoch [1343/2000], Loss D: 1.8562, Loss G: 0.5239\n",
      "Epoch [1344/2000], Loss D: 1.7321, Loss G: 0.5607\n",
      "Epoch [1345/2000], Loss D: 1.6351, Loss G: 0.5989\n",
      "Epoch [1346/2000], Loss D: 1.5347, Loss G: 0.6398\n",
      "Epoch [1347/2000], Loss D: 1.4702, Loss G: 0.6678\n",
      "Epoch [1348/2000], Loss D: 1.4333, Loss G: 0.6841\n",
      "Epoch [1349/2000], Loss D: 1.4238, Loss G: 0.6908\n",
      "Epoch [1350/2000], Loss D: 1.4248, Loss G: 0.6901\n",
      "Epoch [1351/2000], Loss D: 1.4331, Loss G: 0.6831\n",
      "Epoch [1352/2000], Loss D: 1.4442, Loss G: 0.6809\n",
      "Epoch [1353/2000], Loss D: 1.4573, Loss G: 0.6708\n",
      "Epoch [1354/2000], Loss D: 1.4532, Loss G: 0.6701\n",
      "Epoch [1355/2000], Loss D: 1.4483, Loss G: 0.6749\n",
      "Epoch [1356/2000], Loss D: 1.4372, Loss G: 0.6791\n",
      "Epoch [1357/2000], Loss D: 1.4285, Loss G: 0.6812\n",
      "Epoch [1358/2000], Loss D: 1.4243, Loss G: 0.6832\n",
      "Epoch [1359/2000], Loss D: 1.4343, Loss G: 0.6775\n",
      "Epoch [1360/2000], Loss D: 1.4489, Loss G: 0.6727\n",
      "Epoch [1361/2000], Loss D: 1.4590, Loss G: 0.6639\n",
      "Epoch [1362/2000], Loss D: 1.4612, Loss G: 0.6654\n",
      "Epoch [1363/2000], Loss D: 1.4631, Loss G: 0.6645\n",
      "Epoch [1364/2000], Loss D: 1.4588, Loss G: 0.6628\n",
      "Epoch [1365/2000], Loss D: 1.4507, Loss G: 0.6672\n",
      "Epoch [1366/2000], Loss D: 1.4481, Loss G: 0.6702\n",
      "Epoch [1367/2000], Loss D: 1.4404, Loss G: 0.6715\n",
      "Epoch [1368/2000], Loss D: 1.4298, Loss G: 0.6765\n",
      "Epoch [1369/2000], Loss D: 1.4206, Loss G: 0.6818\n",
      "Epoch [1370/2000], Loss D: 1.4130, Loss G: 0.6868\n",
      "Epoch [1371/2000], Loss D: 1.4016, Loss G: 0.6886\n",
      "Epoch [1372/2000], Loss D: 1.3934, Loss G: 0.6952\n",
      "Epoch [1373/2000], Loss D: 1.3862, Loss G: 0.7002\n",
      "Epoch [1374/2000], Loss D: 1.3834, Loss G: 0.6994\n",
      "Epoch [1375/2000], Loss D: 1.3954, Loss G: 0.6958\n",
      "Epoch [1376/2000], Loss D: 1.4158, Loss G: 0.6856\n",
      "Epoch [1377/2000], Loss D: 1.4350, Loss G: 0.6749\n",
      "Epoch [1378/2000], Loss D: 1.4380, Loss G: 0.6750\n",
      "Epoch [1379/2000], Loss D: 1.4229, Loss G: 0.6803\n",
      "Epoch [1380/2000], Loss D: 1.4056, Loss G: 0.6881\n",
      "Epoch [1381/2000], Loss D: 1.3881, Loss G: 0.6976\n",
      "Epoch [1382/2000], Loss D: 1.3648, Loss G: 0.7112\n",
      "Epoch [1383/2000], Loss D: 1.3445, Loss G: 0.7207\n",
      "Epoch [1384/2000], Loss D: 1.3244, Loss G: 0.7316\n",
      "Epoch [1385/2000], Loss D: 1.3114, Loss G: 0.7398\n",
      "Epoch [1386/2000], Loss D: 1.3108, Loss G: 0.7412\n",
      "Epoch [1387/2000], Loss D: 1.3095, Loss G: 0.7415\n",
      "Epoch [1388/2000], Loss D: 1.3214, Loss G: 0.7327\n",
      "Epoch [1389/2000], Loss D: 1.3424, Loss G: 0.7224\n",
      "Epoch [1390/2000], Loss D: 1.3560, Loss G: 0.7127\n",
      "Epoch [1391/2000], Loss D: 1.3725, Loss G: 0.7072\n",
      "Epoch [1392/2000], Loss D: 1.3876, Loss G: 0.7002\n",
      "Epoch [1393/2000], Loss D: 1.3905, Loss G: 0.6946\n",
      "Epoch [1394/2000], Loss D: 1.3876, Loss G: 0.6971\n",
      "Epoch [1395/2000], Loss D: 1.3813, Loss G: 0.7028\n",
      "Epoch [1396/2000], Loss D: 1.3713, Loss G: 0.7082\n",
      "Epoch [1397/2000], Loss D: 1.3619, Loss G: 0.7118\n",
      "Epoch [1398/2000], Loss D: 1.3564, Loss G: 0.7144\n",
      "Epoch [1399/2000], Loss D: 1.3457, Loss G: 0.7185\n",
      "Epoch [1400/2000], Loss D: 1.3440, Loss G: 0.7219\n",
      "Epoch [1401/2000], Loss D: 1.3421, Loss G: 0.7242\n",
      "Epoch [1402/2000], Loss D: 1.3438, Loss G: 0.7238\n",
      "Epoch [1403/2000], Loss D: 1.3536, Loss G: 0.7164\n",
      "Epoch [1404/2000], Loss D: 1.3586, Loss G: 0.7147\n",
      "Epoch [1405/2000], Loss D: 1.3684, Loss G: 0.7095\n",
      "Epoch [1406/2000], Loss D: 1.3759, Loss G: 0.7046\n",
      "Epoch [1407/2000], Loss D: 1.3900, Loss G: 0.7015\n",
      "Epoch [1408/2000], Loss D: 1.4025, Loss G: 0.6916\n",
      "Epoch [1409/2000], Loss D: 1.4160, Loss G: 0.6853\n",
      "Epoch [1410/2000], Loss D: 1.4240, Loss G: 0.6828\n",
      "Epoch [1411/2000], Loss D: 1.4335, Loss G: 0.6789\n",
      "Epoch [1412/2000], Loss D: 1.4442, Loss G: 0.6723\n",
      "Epoch [1413/2000], Loss D: 1.4584, Loss G: 0.6666\n",
      "Epoch [1414/2000], Loss D: 1.4688, Loss G: 0.6605\n",
      "Epoch [1415/2000], Loss D: 1.4796, Loss G: 0.6549\n",
      "Epoch [1416/2000], Loss D: 1.4921, Loss G: 0.6502\n",
      "Epoch [1417/2000], Loss D: 1.4959, Loss G: 0.6495\n",
      "Epoch [1418/2000], Loss D: 1.4977, Loss G: 0.6479\n",
      "Epoch [1419/2000], Loss D: 1.4995, Loss G: 0.6458\n",
      "Epoch [1420/2000], Loss D: 1.4970, Loss G: 0.6485\n",
      "Epoch [1421/2000], Loss D: 1.4927, Loss G: 0.6515\n",
      "Epoch [1422/2000], Loss D: 1.4784, Loss G: 0.6569\n",
      "Epoch [1423/2000], Loss D: 1.4661, Loss G: 0.6639\n",
      "Epoch [1424/2000], Loss D: 1.4461, Loss G: 0.6730\n",
      "Epoch [1425/2000], Loss D: 1.4235, Loss G: 0.6859\n",
      "Epoch [1426/2000], Loss D: 1.4010, Loss G: 0.6975\n",
      "Epoch [1427/2000], Loss D: 1.3725, Loss G: 0.7130\n",
      "Epoch [1428/2000], Loss D: 1.3507, Loss G: 0.7265\n",
      "Epoch [1429/2000], Loss D: 1.3327, Loss G: 0.7359\n",
      "Epoch [1430/2000], Loss D: 1.3169, Loss G: 0.7491\n",
      "Epoch [1431/2000], Loss D: 1.3131, Loss G: 0.7512\n",
      "Epoch [1432/2000], Loss D: 1.3175, Loss G: 0.7522\n",
      "Epoch [1433/2000], Loss D: 1.3401, Loss G: 0.7432\n",
      "Epoch [1434/2000], Loss D: 1.3816, Loss G: 0.7218\n",
      "Epoch [1435/2000], Loss D: 1.4351, Loss G: 0.6950\n",
      "Epoch [1436/2000], Loss D: 1.4944, Loss G: 0.6669\n",
      "Epoch [1437/2000], Loss D: 1.5248, Loss G: 0.6522\n",
      "Epoch [1438/2000], Loss D: 1.5193, Loss G: 0.6518\n",
      "Epoch [1439/2000], Loss D: 1.4998, Loss G: 0.6604\n",
      "Epoch [1440/2000], Loss D: 1.4655, Loss G: 0.6769\n",
      "Epoch [1441/2000], Loss D: 1.4117, Loss G: 0.7022\n",
      "Epoch [1442/2000], Loss D: 1.3664, Loss G: 0.7186\n",
      "Epoch [1443/2000], Loss D: 1.3158, Loss G: 0.7474\n",
      "Epoch [1444/2000], Loss D: 1.2720, Loss G: 0.7760\n",
      "Epoch [1445/2000], Loss D: 1.3165, Loss G: 0.8127\n",
      "Epoch [1446/2000], Loss D: 1.2613, Loss G: 0.8450\n",
      "Epoch [1447/2000], Loss D: 1.2118, Loss G: 0.8764\n",
      "Epoch [1448/2000], Loss D: 1.0944, Loss G: 0.8951\n",
      "Epoch [1449/2000], Loss D: 1.1141, Loss G: 0.8957\n",
      "Epoch [1450/2000], Loss D: 1.1870, Loss G: 0.8600\n",
      "Epoch [1451/2000], Loss D: 1.3571, Loss G: 0.7629\n",
      "Epoch [1452/2000], Loss D: 1.7070, Loss G: 0.6192\n",
      "Epoch [1453/2000], Loss D: 2.1478, Loss G: 0.4777\n",
      "Epoch [1454/2000], Loss D: 1.8500, Loss G: 6.6495\n",
      "Epoch [1455/2000], Loss D: 1.1049, Loss G: 11.7201\n",
      "Epoch [1456/2000], Loss D: 1.6963, Loss G: 6.9600\n",
      "Epoch [1457/2000], Loss D: 0.7563, Loss G: 9.3560\n",
      "Epoch [1458/2000], Loss D: 4.3075, Loss G: 5.4292\n",
      "Epoch [1459/2000], Loss D: 1.6551, Loss G: 3.2621\n",
      "Epoch [1460/2000], Loss D: 1.4388, Loss G: 1.2188\n",
      "Epoch [1461/2000], Loss D: 1.2551, Loss G: 1.8006\n",
      "Epoch [1462/2000], Loss D: 0.9700, Loss G: 1.9685\n",
      "Epoch [1463/2000], Loss D: 0.9804, Loss G: 1.7722\n",
      "Epoch [1464/2000], Loss D: 0.9207, Loss G: 1.9210\n",
      "Epoch [1465/2000], Loss D: 0.9148, Loss G: 2.1945\n",
      "Epoch [1466/2000], Loss D: 0.9272, Loss G: 2.2936\n",
      "Epoch [1467/2000], Loss D: 1.0589, Loss G: 1.9442\n",
      "Epoch [1468/2000], Loss D: 1.0759, Loss G: 1.8002\n",
      "Epoch [1469/2000], Loss D: 1.0613, Loss G: 1.9454\n",
      "Epoch [1470/2000], Loss D: 1.2189, Loss G: 1.3236\n",
      "Epoch [1471/2000], Loss D: 1.1086, Loss G: 1.5003\n",
      "Epoch [1472/2000], Loss D: 1.0816, Loss G: 1.0888\n",
      "Epoch [1473/2000], Loss D: 1.0229, Loss G: 1.1584\n",
      "Epoch [1474/2000], Loss D: 0.9776, Loss G: 1.2098\n",
      "Epoch [1475/2000], Loss D: 1.0173, Loss G: 1.0949\n",
      "Epoch [1476/2000], Loss D: 1.1448, Loss G: 1.0601\n",
      "Epoch [1477/2000], Loss D: 1.1859, Loss G: 1.4816\n",
      "Epoch [1478/2000], Loss D: 1.2814, Loss G: 1.0527\n",
      "Epoch [1479/2000], Loss D: 1.2219, Loss G: 0.8456\n",
      "Epoch [1480/2000], Loss D: 1.1893, Loss G: 0.9502\n",
      "Epoch [1481/2000], Loss D: 1.4127, Loss G: 0.8032\n",
      "Epoch [1482/2000], Loss D: 1.5320, Loss G: 0.7847\n",
      "Epoch [1483/2000], Loss D: 1.3123, Loss G: 0.8025\n",
      "Epoch [1484/2000], Loss D: 1.2238, Loss G: 1.0171\n",
      "Epoch [1485/2000], Loss D: 1.1035, Loss G: 1.0758\n",
      "Epoch [1486/2000], Loss D: 1.0282, Loss G: 1.0949\n",
      "Epoch [1487/2000], Loss D: 1.0188, Loss G: 1.1372\n",
      "Epoch [1488/2000], Loss D: 1.1473, Loss G: 1.0474\n",
      "Epoch [1489/2000], Loss D: 1.3318, Loss G: 0.9070\n",
      "Epoch [1490/2000], Loss D: 1.3452, Loss G: 0.9976\n",
      "Epoch [1491/2000], Loss D: 1.3261, Loss G: 0.8387\n",
      "Epoch [1492/2000], Loss D: 1.2125, Loss G: 0.8974\n",
      "Epoch [1493/2000], Loss D: 1.1143, Loss G: 0.9688\n",
      "Epoch [1494/2000], Loss D: 1.1058, Loss G: 1.0146\n",
      "Epoch [1495/2000], Loss D: 1.3487, Loss G: 0.7839\n",
      "Epoch [1496/2000], Loss D: 1.2696, Loss G: 0.7865\n",
      "Epoch [1497/2000], Loss D: 1.0288, Loss G: 1.0183\n",
      "Epoch [1498/2000], Loss D: 0.8016, Loss G: 1.2692\n",
      "Epoch [1499/2000], Loss D: 0.8298, Loss G: 1.1758\n",
      "Epoch [1500/2000], Loss D: 0.9134, Loss G: 1.0932\n",
      "Epoch [1501/2000], Loss D: 1.0103, Loss G: 1.0971\n",
      "Epoch [1502/2000], Loss D: 1.3065, Loss G: 0.9836\n",
      "Epoch [1503/2000], Loss D: 1.4200, Loss G: 0.7846\n",
      "Epoch [1504/2000], Loss D: 1.4047, Loss G: 0.7220\n",
      "Epoch [1505/2000], Loss D: 1.2584, Loss G: 0.9060\n",
      "Epoch [1506/2000], Loss D: 1.0940, Loss G: 1.9215\n",
      "Epoch [1507/2000], Loss D: 1.8246, Loss G: 0.5987\n",
      "Epoch [1508/2000], Loss D: 1.2709, Loss G: 0.9752\n",
      "Epoch [1509/2000], Loss D: 0.7061, Loss G: 1.5684\n",
      "Epoch [1510/2000], Loss D: 0.5669, Loss G: 1.3642\n",
      "Epoch [1511/2000], Loss D: 0.6295, Loss G: 1.4145\n",
      "Epoch [1512/2000], Loss D: 0.5758, Loss G: 1.6376\n",
      "Epoch [1513/2000], Loss D: 0.5040, Loss G: 1.6160\n",
      "Epoch [1514/2000], Loss D: 0.5635, Loss G: 1.6909\n",
      "Epoch [1515/2000], Loss D: 0.6208, Loss G: 1.6374\n",
      "Epoch [1516/2000], Loss D: 0.7349, Loss G: 1.4401\n",
      "Epoch [1517/2000], Loss D: 0.9134, Loss G: 1.2776\n",
      "Epoch [1518/2000], Loss D: 1.3024, Loss G: 1.1172\n",
      "Epoch [1519/2000], Loss D: 1.7550, Loss G: 0.7603\n",
      "Epoch [1520/2000], Loss D: 1.8862, Loss G: 0.5651\n",
      "Epoch [1521/2000], Loss D: 1.7939, Loss G: 0.5398\n",
      "Epoch [1522/2000], Loss D: 1.6071, Loss G: 0.8706\n",
      "Epoch [1523/2000], Loss D: 1.4478, Loss G: 1.5353\n",
      "Epoch [1524/2000], Loss D: 2.3006, Loss G: 0.4662\n",
      "Epoch [1525/2000], Loss D: 1.5067, Loss G: 0.9557\n",
      "Epoch [1526/2000], Loss D: 0.7755, Loss G: 1.6325\n",
      "Epoch [1527/2000], Loss D: 0.7488, Loss G: 1.0594\n",
      "Epoch [1528/2000], Loss D: 0.7150, Loss G: 1.2628\n",
      "Epoch [1529/2000], Loss D: 0.6153, Loss G: 1.6968\n",
      "Epoch [1530/2000], Loss D: 0.7112, Loss G: 1.6024\n",
      "Epoch [1531/2000], Loss D: 0.7363, Loss G: 1.6052\n",
      "Epoch [1532/2000], Loss D: 0.9010, Loss G: 1.3357\n",
      "Epoch [1533/2000], Loss D: 1.2537, Loss G: 1.1387\n",
      "Epoch [1534/2000], Loss D: 1.5783, Loss G: 1.0620\n",
      "Epoch [1535/2000], Loss D: 1.7813, Loss G: 0.7346\n",
      "Epoch [1536/2000], Loss D: 1.7187, Loss G: 0.6006\n",
      "Epoch [1537/2000], Loss D: 1.6115, Loss G: 0.6321\n",
      "Epoch [1538/2000], Loss D: 1.4803, Loss G: 0.6928\n",
      "Epoch [1539/2000], Loss D: 1.3721, Loss G: 0.8085\n",
      "Epoch [1540/2000], Loss D: 1.2356, Loss G: 1.0704\n",
      "Epoch [1541/2000], Loss D: 1.4099, Loss G: 1.0558\n",
      "Epoch [1542/2000], Loss D: 1.6672, Loss G: 0.7867\n",
      "Epoch [1543/2000], Loss D: 1.6485, Loss G: 0.7538\n",
      "Epoch [1544/2000], Loss D: 1.4699, Loss G: 0.7163\n",
      "Epoch [1545/2000], Loss D: 1.3411, Loss G: 0.7171\n",
      "Epoch [1546/2000], Loss D: 1.2680, Loss G: 0.7603\n",
      "Epoch [1547/2000], Loss D: 1.2060, Loss G: 0.8214\n",
      "Epoch [1548/2000], Loss D: 1.1637, Loss G: 0.8591\n",
      "Epoch [1549/2000], Loss D: 1.1434, Loss G: 0.8639\n",
      "Epoch [1550/2000], Loss D: 1.1287, Loss G: 0.8680\n",
      "Epoch [1551/2000], Loss D: 1.1311, Loss G: 0.8753\n",
      "Epoch [1552/2000], Loss D: 1.1213, Loss G: 0.8895\n",
      "Epoch [1553/2000], Loss D: 1.1415, Loss G: 0.8860\n",
      "Epoch [1554/2000], Loss D: 1.1654, Loss G: 0.8756\n",
      "Epoch [1555/2000], Loss D: 1.2165, Loss G: 0.8449\n",
      "Epoch [1556/2000], Loss D: 1.2697, Loss G: 0.8195\n",
      "Epoch [1557/2000], Loss D: 1.2995, Loss G: 0.7986\n",
      "Epoch [1558/2000], Loss D: 1.3140, Loss G: 0.7833\n",
      "Epoch [1559/2000], Loss D: 1.3129, Loss G: 0.7811\n",
      "Epoch [1560/2000], Loss D: 1.3189, Loss G: 0.7768\n",
      "Epoch [1561/2000], Loss D: 1.3401, Loss G: 0.7590\n",
      "Epoch [1562/2000], Loss D: 1.3251, Loss G: 0.7649\n",
      "Epoch [1563/2000], Loss D: 1.2739, Loss G: 0.7889\n",
      "Epoch [1564/2000], Loss D: 1.2145, Loss G: 0.8242\n",
      "Epoch [1565/2000], Loss D: 1.1249, Loss G: 0.8829\n",
      "Epoch [1566/2000], Loss D: 1.0677, Loss G: 0.9490\n",
      "Epoch [1567/2000], Loss D: 1.0719, Loss G: 0.9690\n",
      "Epoch [1568/2000], Loss D: 1.3630, Loss G: 0.8113\n",
      "Epoch [1569/2000], Loss D: 1.6053, Loss G: 0.7850\n",
      "Epoch [1570/2000], Loss D: 1.6741, Loss G: 0.7076\n",
      "Epoch [1571/2000], Loss D: 1.5454, Loss G: 0.6891\n",
      "Epoch [1572/2000], Loss D: 1.4668, Loss G: 0.6857\n",
      "Epoch [1573/2000], Loss D: 1.4018, Loss G: 0.7391\n",
      "Epoch [1574/2000], Loss D: 1.3305, Loss G: 0.7934\n",
      "Epoch [1575/2000], Loss D: 1.3019, Loss G: 0.8204\n",
      "Epoch [1576/2000], Loss D: 1.2861, Loss G: 0.8257\n",
      "Epoch [1577/2000], Loss D: 1.2879, Loss G: 0.8506\n",
      "Epoch [1578/2000], Loss D: 1.3878, Loss G: 0.8096\n",
      "Epoch [1579/2000], Loss D: 1.6949, Loss G: 0.6580\n",
      "Epoch [1580/2000], Loss D: 2.0359, Loss G: 0.5542\n",
      "Epoch [1581/2000], Loss D: 2.1478, Loss G: 0.5161\n",
      "Epoch [1582/2000], Loss D: 2.0228, Loss G: 0.5075\n",
      "Epoch [1583/2000], Loss D: 1.9039, Loss G: 0.5162\n",
      "Epoch [1584/2000], Loss D: 1.8208, Loss G: 0.5269\n",
      "Epoch [1585/2000], Loss D: 1.7535, Loss G: 0.5527\n",
      "Epoch [1586/2000], Loss D: 1.6937, Loss G: 0.5796\n",
      "Epoch [1587/2000], Loss D: 1.6429, Loss G: 0.6015\n",
      "Epoch [1588/2000], Loss D: 1.5931, Loss G: 0.6233\n",
      "Epoch [1589/2000], Loss D: 1.5458, Loss G: 0.6514\n",
      "Epoch [1590/2000], Loss D: 1.4577, Loss G: 0.7236\n",
      "Epoch [1591/2000], Loss D: 1.3718, Loss G: 1.1291\n",
      "Epoch [1592/2000], Loss D: 1.9864, Loss G: 0.7104\n",
      "Epoch [1593/2000], Loss D: 1.6390, Loss G: 0.8630\n",
      "Epoch [1594/2000], Loss D: 1.4493, Loss G: 0.8360\n",
      "Epoch [1595/2000], Loss D: 1.3838, Loss G: 0.8262\n",
      "Epoch [1596/2000], Loss D: 1.3095, Loss G: 0.8349\n",
      "Epoch [1597/2000], Loss D: 1.4111, Loss G: 0.8598\n",
      "Epoch [1598/2000], Loss D: 1.4490, Loss G: 1.1044\n",
      "Epoch [1599/2000], Loss D: 1.4674, Loss G: 0.8915\n",
      "Epoch [1600/2000], Loss D: 1.4373, Loss G: 1.0579\n",
      "Epoch [1601/2000], Loss D: 1.2047, Loss G: 1.2346\n",
      "Epoch [1602/2000], Loss D: 1.2929, Loss G: 1.2729\n",
      "Epoch [1603/2000], Loss D: 1.6430, Loss G: 0.8429\n",
      "Epoch [1604/2000], Loss D: 1.1605, Loss G: 0.8231\n",
      "Epoch [1605/2000], Loss D: 1.1913, Loss G: 0.8344\n",
      "Epoch [1606/2000], Loss D: 1.1814, Loss G: 0.8341\n",
      "Epoch [1607/2000], Loss D: 1.1711, Loss G: 0.8303\n",
      "Epoch [1608/2000], Loss D: 1.1452, Loss G: 0.8359\n",
      "Epoch [1609/2000], Loss D: 1.1283, Loss G: 0.8496\n",
      "Epoch [1610/2000], Loss D: 1.1175, Loss G: 0.8670\n",
      "Epoch [1611/2000], Loss D: 1.1140, Loss G: 0.8744\n",
      "Epoch [1612/2000], Loss D: 1.1071, Loss G: 0.8800\n",
      "Epoch [1613/2000], Loss D: 1.1049, Loss G: 0.8819\n",
      "Epoch [1614/2000], Loss D: 1.1016, Loss G: 0.8731\n",
      "Epoch [1615/2000], Loss D: 1.1006, Loss G: 0.8799\n",
      "Epoch [1616/2000], Loss D: 1.0958, Loss G: 0.8805\n",
      "Epoch [1617/2000], Loss D: 1.1128, Loss G: 0.8815\n",
      "Epoch [1618/2000], Loss D: 1.1180, Loss G: 0.8745\n",
      "Epoch [1619/2000], Loss D: 1.1493, Loss G: 0.8500\n",
      "Epoch [1620/2000], Loss D: 1.1442, Loss G: 0.8550\n",
      "Epoch [1621/2000], Loss D: 1.1680, Loss G: 0.8359\n",
      "Epoch [1622/2000], Loss D: 1.1941, Loss G: 0.8316\n",
      "Epoch [1623/2000], Loss D: 1.2312, Loss G: 0.8118\n",
      "Epoch [1624/2000], Loss D: 1.2517, Loss G: 0.7898\n",
      "Epoch [1625/2000], Loss D: 1.2789, Loss G: 0.7828\n",
      "Epoch [1626/2000], Loss D: 1.3165, Loss G: 0.7559\n",
      "Epoch [1627/2000], Loss D: 1.3635, Loss G: 0.7330\n",
      "Epoch [1628/2000], Loss D: 1.4301, Loss G: 0.7088\n",
      "Epoch [1629/2000], Loss D: 1.4763, Loss G: 0.6859\n",
      "Epoch [1630/2000], Loss D: 1.5296, Loss G: 0.6532\n",
      "Epoch [1631/2000], Loss D: 1.6169, Loss G: 0.6141\n",
      "Epoch [1632/2000], Loss D: 1.6733, Loss G: 0.6029\n",
      "Epoch [1633/2000], Loss D: 1.7672, Loss G: 0.5739\n",
      "Epoch [1634/2000], Loss D: 1.8188, Loss G: 0.5452\n",
      "Epoch [1635/2000], Loss D: 1.8378, Loss G: 0.5297\n",
      "Epoch [1636/2000], Loss D: 1.8419, Loss G: 0.5358\n",
      "Epoch [1637/2000], Loss D: 1.8213, Loss G: 0.5411\n",
      "Epoch [1638/2000], Loss D: 1.7946, Loss G: 0.5488\n",
      "Epoch [1639/2000], Loss D: 1.7549, Loss G: 0.5582\n",
      "Epoch [1640/2000], Loss D: 1.7412, Loss G: 0.5631\n",
      "Epoch [1641/2000], Loss D: 1.7186, Loss G: 0.5748\n",
      "Epoch [1642/2000], Loss D: 1.6889, Loss G: 0.5781\n",
      "Epoch [1643/2000], Loss D: 1.6639, Loss G: 0.5866\n",
      "Epoch [1644/2000], Loss D: 1.6227, Loss G: 0.6033\n",
      "Epoch [1645/2000], Loss D: 1.6023, Loss G: 0.6137\n",
      "Epoch [1646/2000], Loss D: 1.5650, Loss G: 0.6295\n",
      "Epoch [1647/2000], Loss D: 1.5506, Loss G: 0.6368\n",
      "Epoch [1648/2000], Loss D: 1.5267, Loss G: 0.6360\n",
      "Epoch [1649/2000], Loss D: 1.4925, Loss G: 0.6525\n",
      "Epoch [1650/2000], Loss D: 1.4470, Loss G: 0.6798\n",
      "Epoch [1651/2000], Loss D: 1.3962, Loss G: 0.7029\n",
      "Epoch [1652/2000], Loss D: 1.3430, Loss G: 0.7336\n",
      "Epoch [1653/2000], Loss D: 1.3277, Loss G: 0.7498\n",
      "Epoch [1654/2000], Loss D: 1.2892, Loss G: 0.7781\n",
      "Epoch [1655/2000], Loss D: 1.2856, Loss G: 0.7855\n",
      "Epoch [1656/2000], Loss D: 1.2791, Loss G: 0.7995\n",
      "Epoch [1657/2000], Loss D: 1.3419, Loss G: 0.7769\n",
      "Epoch [1658/2000], Loss D: 1.4157, Loss G: 0.7564\n",
      "Epoch [1659/2000], Loss D: 1.5188, Loss G: 0.7105\n",
      "Epoch [1660/2000], Loss D: 1.5940, Loss G: 0.6890\n",
      "Epoch [1661/2000], Loss D: 1.6643, Loss G: 0.6530\n",
      "Epoch [1662/2000], Loss D: 1.6818, Loss G: 0.6192\n",
      "Epoch [1663/2000], Loss D: 1.6552, Loss G: 0.6269\n",
      "Epoch [1664/2000], Loss D: 1.5747, Loss G: 0.6473\n",
      "Epoch [1665/2000], Loss D: 1.4984, Loss G: 0.6744\n",
      "Epoch [1666/2000], Loss D: 1.4010, Loss G: 0.7225\n",
      "Epoch [1667/2000], Loss D: 1.2958, Loss G: 0.7989\n",
      "Epoch [1668/2000], Loss D: 1.2139, Loss G: 0.8210\n",
      "Epoch [1669/2000], Loss D: 1.1437, Loss G: 0.8660\n",
      "Epoch [1670/2000], Loss D: 1.0650, Loss G: 0.9928\n",
      "Epoch [1671/2000], Loss D: 1.0198, Loss G: 0.9712\n",
      "Epoch [1672/2000], Loss D: 0.9862, Loss G: 1.0153\n",
      "Epoch [1673/2000], Loss D: 0.9521, Loss G: 1.0538\n",
      "Epoch [1674/2000], Loss D: 0.9777, Loss G: 1.0173\n",
      "Epoch [1675/2000], Loss D: 0.9713, Loss G: 0.9982\n",
      "Epoch [1676/2000], Loss D: 1.0023, Loss G: 0.9771\n",
      "Epoch [1677/2000], Loss D: 1.0334, Loss G: 0.9445\n",
      "Epoch [1678/2000], Loss D: 1.1046, Loss G: 0.8959\n",
      "Epoch [1679/2000], Loss D: 1.1785, Loss G: 0.8625\n",
      "Epoch [1680/2000], Loss D: 1.2244, Loss G: 0.8296\n",
      "Epoch [1681/2000], Loss D: 1.2860, Loss G: 0.7964\n",
      "Epoch [1682/2000], Loss D: 1.4073, Loss G: 0.7301\n",
      "Epoch [1683/2000], Loss D: 1.4859, Loss G: 0.6746\n",
      "Epoch [1684/2000], Loss D: 1.4976, Loss G: 0.6664\n",
      "Epoch [1685/2000], Loss D: 1.4649, Loss G: 0.6802\n",
      "Epoch [1686/2000], Loss D: 1.4481, Loss G: 0.6899\n",
      "Epoch [1687/2000], Loss D: 1.4487, Loss G: 0.6888\n",
      "Epoch [1688/2000], Loss D: 1.4268, Loss G: 0.6963\n",
      "Epoch [1689/2000], Loss D: 1.4209, Loss G: 0.7076\n",
      "Epoch [1690/2000], Loss D: 1.3946, Loss G: 0.7239\n",
      "Epoch [1691/2000], Loss D: 1.3860, Loss G: 0.7304\n",
      "Epoch [1692/2000], Loss D: 1.3623, Loss G: 0.7398\n",
      "Epoch [1693/2000], Loss D: 1.3463, Loss G: 0.7476\n",
      "Epoch [1694/2000], Loss D: 1.3305, Loss G: 0.7618\n",
      "Epoch [1695/2000], Loss D: 1.3235, Loss G: 0.7653\n",
      "Epoch [1696/2000], Loss D: 1.3656, Loss G: 0.7452\n",
      "Epoch [1697/2000], Loss D: 1.4210, Loss G: 0.7192\n",
      "Epoch [1698/2000], Loss D: 1.4933, Loss G: 0.6874\n",
      "Epoch [1699/2000], Loss D: 1.5730, Loss G: 0.6489\n",
      "Epoch [1700/2000], Loss D: 1.6334, Loss G: 0.6229\n",
      "Epoch [1701/2000], Loss D: 1.6626, Loss G: 0.6112\n",
      "Epoch [1702/2000], Loss D: 1.6802, Loss G: 0.6031\n",
      "Epoch [1703/2000], Loss D: 1.6875, Loss G: 0.5983\n",
      "Epoch [1704/2000], Loss D: 1.6832, Loss G: 0.5964\n",
      "Epoch [1705/2000], Loss D: 1.6869, Loss G: 0.5938\n",
      "Epoch [1706/2000], Loss D: 1.7473, Loss G: 0.5702\n",
      "Epoch [1707/2000], Loss D: 1.8043, Loss G: 0.5440\n",
      "Epoch [1708/2000], Loss D: 1.8243, Loss G: 0.5344\n",
      "Epoch [1709/2000], Loss D: 1.8009, Loss G: 0.5402\n",
      "Epoch [1710/2000], Loss D: 1.7419, Loss G: 0.5616\n",
      "Epoch [1711/2000], Loss D: 1.6572, Loss G: 0.5926\n",
      "Epoch [1712/2000], Loss D: 1.5753, Loss G: 0.6290\n",
      "Epoch [1713/2000], Loss D: 1.4883, Loss G: 0.6722\n",
      "Epoch [1714/2000], Loss D: 1.4125, Loss G: 0.7164\n",
      "Epoch [1715/2000], Loss D: 1.3345, Loss G: 0.7641\n",
      "Epoch [1716/2000], Loss D: 1.2668, Loss G: 0.8076\n",
      "Epoch [1717/2000], Loss D: 1.2211, Loss G: 0.8428\n",
      "Epoch [1718/2000], Loss D: 1.1933, Loss G: 0.8647\n",
      "Epoch [1719/2000], Loss D: 1.1664, Loss G: 0.8933\n",
      "Epoch [1720/2000], Loss D: 1.1096, Loss G: 0.9434\n",
      "Epoch [1721/2000], Loss D: 1.0258, Loss G: 1.0136\n",
      "Epoch [1722/2000], Loss D: 0.9725, Loss G: 1.0515\n",
      "Epoch [1723/2000], Loss D: 1.0242, Loss G: 1.0216\n",
      "Epoch [1724/2000], Loss D: 1.2288, Loss G: 0.9435\n",
      "Epoch [1725/2000], Loss D: 1.5530, Loss G: 0.8147\n",
      "Epoch [1726/2000], Loss D: 1.8569, Loss G: 0.6970\n",
      "Epoch [1727/2000], Loss D: 1.8865, Loss G: 0.6614\n",
      "Epoch [1728/2000], Loss D: 1.5832, Loss G: 0.7327\n",
      "Epoch [1729/2000], Loss D: 1.1818, Loss G: 0.8935\n",
      "Epoch [1730/2000], Loss D: 1.0136, Loss G: 0.9972\n",
      "Epoch [1731/2000], Loss D: 0.8934, Loss G: 1.0918\n",
      "Epoch [1732/2000], Loss D: 0.8698, Loss G: 1.1150\n",
      "Epoch [1733/2000], Loss D: 0.8546, Loss G: 1.1518\n",
      "Epoch [1734/2000], Loss D: 0.8384, Loss G: 1.1636\n",
      "Epoch [1735/2000], Loss D: 0.8574, Loss G: 1.1605\n",
      "Epoch [1736/2000], Loss D: 0.8580, Loss G: 1.1709\n",
      "Epoch [1737/2000], Loss D: 0.8758, Loss G: 1.1670\n",
      "Epoch [1738/2000], Loss D: 0.9621, Loss G: 1.1580\n",
      "Epoch [1739/2000], Loss D: 1.0581, Loss G: 1.0535\n",
      "Epoch [1740/2000], Loss D: 1.2640, Loss G: 0.9403\n",
      "Epoch [1741/2000], Loss D: 1.5004, Loss G: 0.8134\n",
      "Epoch [1742/2000], Loss D: 1.5512, Loss G: 0.7339\n",
      "Epoch [1743/2000], Loss D: 1.4020, Loss G: 0.7553\n",
      "Epoch [1744/2000], Loss D: 1.2363, Loss G: 0.8287\n",
      "Epoch [1745/2000], Loss D: 1.1984, Loss G: 0.8560\n",
      "Epoch [1746/2000], Loss D: 1.2276, Loss G: 0.8532\n",
      "Epoch [1747/2000], Loss D: 1.2432, Loss G: 0.8742\n",
      "Epoch [1748/2000], Loss D: 1.3026, Loss G: 0.8473\n",
      "Epoch [1749/2000], Loss D: 1.3556, Loss G: 0.8203\n",
      "Epoch [1750/2000], Loss D: 1.3963, Loss G: 0.7986\n",
      "Epoch [1751/2000], Loss D: 1.4282, Loss G: 0.7822\n",
      "Epoch [1752/2000], Loss D: 1.4825, Loss G: 0.7429\n",
      "Epoch [1753/2000], Loss D: 1.5733, Loss G: 0.6779\n",
      "Epoch [1754/2000], Loss D: 1.6392, Loss G: 0.6342\n",
      "Epoch [1755/2000], Loss D: 1.6686, Loss G: 0.6146\n",
      "Epoch [1756/2000], Loss D: 1.6409, Loss G: 0.6228\n",
      "Epoch [1757/2000], Loss D: 1.5479, Loss G: 0.6639\n",
      "Epoch [1758/2000], Loss D: 1.4524, Loss G: 0.7404\n",
      "Epoch [1759/2000], Loss D: 1.2686, Loss G: 0.8545\n",
      "Epoch [1760/2000], Loss D: 1.1161, Loss G: 0.9837\n",
      "Epoch [1761/2000], Loss D: 1.1520, Loss G: 0.9837\n",
      "Epoch [1762/2000], Loss D: 1.4339, Loss G: 0.8014\n",
      "Epoch [1763/2000], Loss D: 1.8803, Loss G: 0.6263\n",
      "Epoch [1764/2000], Loss D: 2.1521, Loss G: 0.5064\n",
      "Epoch [1765/2000], Loss D: 1.6342, Loss G: 0.7512\n",
      "Epoch [1766/2000], Loss D: 1.0105, Loss G: 1.0660\n",
      "Epoch [1767/2000], Loss D: 0.9654, Loss G: 1.1155\n",
      "Epoch [1768/2000], Loss D: 1.1051, Loss G: 1.0306\n",
      "Epoch [1769/2000], Loss D: 1.3597, Loss G: 0.8772\n",
      "Epoch [1770/2000], Loss D: 1.7885, Loss G: 0.6927\n",
      "Epoch [1771/2000], Loss D: 2.1227, Loss G: 0.5515\n",
      "Epoch [1772/2000], Loss D: 2.1592, Loss G: 0.4954\n",
      "Epoch [1773/2000], Loss D: 2.0026, Loss G: 0.5071\n",
      "Epoch [1774/2000], Loss D: 1.8023, Loss G: 0.5607\n",
      "Epoch [1775/2000], Loss D: 1.6321, Loss G: 0.6207\n",
      "Epoch [1776/2000], Loss D: 1.5070, Loss G: 0.6772\n",
      "Epoch [1777/2000], Loss D: 1.3692, Loss G: 0.7558\n",
      "Epoch [1778/2000], Loss D: 1.1763, Loss G: 0.9064\n",
      "Epoch [1779/2000], Loss D: 0.9424, Loss G: 1.1394\n",
      "Epoch [1780/2000], Loss D: 0.7715, Loss G: 1.2756\n",
      "Epoch [1781/2000], Loss D: 0.7544, Loss G: 1.2710\n",
      "Epoch [1782/2000], Loss D: 0.7515, Loss G: 1.2374\n",
      "Epoch [1783/2000], Loss D: 0.7777, Loss G: 1.2422\n",
      "Epoch [1784/2000], Loss D: 0.8590, Loss G: 1.1957\n",
      "Epoch [1785/2000], Loss D: 1.1668, Loss G: 0.9934\n",
      "Epoch [1786/2000], Loss D: 1.6700, Loss G: 0.7083\n",
      "Epoch [1787/2000], Loss D: 2.0190, Loss G: 0.5571\n",
      "Epoch [1788/2000], Loss D: 1.7960, Loss G: 0.6350\n",
      "Epoch [1789/2000], Loss D: 1.5984, Loss G: 0.6781\n",
      "Epoch [1790/2000], Loss D: 1.5387, Loss G: 0.6786\n",
      "Epoch [1791/2000], Loss D: 1.5056, Loss G: 0.6845\n",
      "Epoch [1792/2000], Loss D: 1.4276, Loss G: 0.7265\n",
      "Epoch [1793/2000], Loss D: 1.3580, Loss G: 0.7527\n",
      "Epoch [1794/2000], Loss D: 1.2887, Loss G: 0.7932\n",
      "Epoch [1795/2000], Loss D: 1.2276, Loss G: 0.8371\n",
      "Epoch [1796/2000], Loss D: 1.1996, Loss G: 0.8566\n",
      "Epoch [1797/2000], Loss D: 1.2110, Loss G: 0.8572\n",
      "Epoch [1798/2000], Loss D: 1.2906, Loss G: 0.8150\n",
      "Epoch [1799/2000], Loss D: 1.4824, Loss G: 0.7082\n",
      "Epoch [1800/2000], Loss D: 1.7561, Loss G: 0.5988\n",
      "Epoch [1801/2000], Loss D: 1.9511, Loss G: 0.5498\n",
      "Epoch [1802/2000], Loss D: 1.9711, Loss G: 0.5362\n",
      "Epoch [1803/2000], Loss D: 1.8652, Loss G: 0.5535\n",
      "Epoch [1804/2000], Loss D: 1.6996, Loss G: 0.6015\n",
      "Epoch [1805/2000], Loss D: 1.4903, Loss G: 0.7041\n",
      "Epoch [1806/2000], Loss D: 1.1678, Loss G: 0.9409\n",
      "Epoch [1807/2000], Loss D: 0.9984, Loss G: 1.0365\n",
      "Epoch [1808/2000], Loss D: 1.0617, Loss G: 1.0390\n",
      "Epoch [1809/2000], Loss D: 1.2752, Loss G: 0.8891\n",
      "Epoch [1810/2000], Loss D: 1.5864, Loss G: 0.6912\n",
      "Epoch [1811/2000], Loss D: 1.7794, Loss G: 0.5960\n",
      "Epoch [1812/2000], Loss D: 1.6834, Loss G: 0.6208\n",
      "Epoch [1813/2000], Loss D: 1.4493, Loss G: 0.7193\n",
      "Epoch [1814/2000], Loss D: 1.2995, Loss G: 0.7960\n",
      "Epoch [1815/2000], Loss D: 1.1946, Loss G: 0.8569\n",
      "Epoch [1816/2000], Loss D: 1.0927, Loss G: 0.9401\n",
      "Epoch [1817/2000], Loss D: 1.0348, Loss G: 0.9863\n",
      "Epoch [1818/2000], Loss D: 1.0342, Loss G: 0.9811\n",
      "Epoch [1819/2000], Loss D: 1.0951, Loss G: 0.9448\n",
      "Epoch [1820/2000], Loss D: 1.2391, Loss G: 0.8662\n",
      "Epoch [1821/2000], Loss D: 1.4024, Loss G: 0.7814\n",
      "Epoch [1822/2000], Loss D: 1.4952, Loss G: 0.7447\n",
      "Epoch [1823/2000], Loss D: 1.4916, Loss G: 0.7383\n",
      "Epoch [1824/2000], Loss D: 1.3960, Loss G: 0.7648\n",
      "Epoch [1825/2000], Loss D: 1.2664, Loss G: 0.8142\n",
      "Epoch [1826/2000], Loss D: 1.1322, Loss G: 0.8952\n",
      "Epoch [1827/2000], Loss D: 0.9585, Loss G: 1.0687\n",
      "Epoch [1828/2000], Loss D: 0.8373, Loss G: 1.2503\n",
      "Epoch [1829/2000], Loss D: 1.0077, Loss G: 1.0455\n",
      "Epoch [1830/2000], Loss D: 1.4273, Loss G: 0.7858\n",
      "Epoch [1831/2000], Loss D: 1.5586, Loss G: 0.7490\n",
      "Epoch [1832/2000], Loss D: 0.6593, Loss G: 1.8836\n",
      "Epoch [1833/2000], Loss D: 0.5784, Loss G: 7.8239\n",
      "Epoch [1834/2000], Loss D: 2.3372, Loss G: 3.9767\n",
      "Epoch [1835/2000], Loss D: 3.3281, Loss G: 3.3663\n",
      "Epoch [1836/2000], Loss D: 1.5697, Loss G: 0.8542\n",
      "Epoch [1837/2000], Loss D: 2.0218, Loss G: 0.6525\n",
      "Epoch [1838/2000], Loss D: 2.5292, Loss G: 0.5498\n",
      "Epoch [1839/2000], Loss D: 2.0020, Loss G: 0.5469\n",
      "Epoch [1840/2000], Loss D: 1.6338, Loss G: 0.6256\n",
      "Epoch [1841/2000], Loss D: 1.3097, Loss G: 0.7889\n",
      "Epoch [1842/2000], Loss D: 1.2850, Loss G: 0.8345\n",
      "Epoch [1843/2000], Loss D: 1.4335, Loss G: 0.7865\n",
      "Epoch [1844/2000], Loss D: 1.4641, Loss G: 0.7679\n",
      "Epoch [1845/2000], Loss D: 1.4031, Loss G: 0.8239\n",
      "Epoch [1846/2000], Loss D: 1.2610, Loss G: 0.9190\n",
      "Epoch [1847/2000], Loss D: 1.1700, Loss G: 0.9744\n",
      "Epoch [1848/2000], Loss D: 1.1455, Loss G: 1.0291\n",
      "Epoch [1849/2000], Loss D: 1.1299, Loss G: 1.0724\n",
      "Epoch [1850/2000], Loss D: 1.2200, Loss G: 1.0355\n",
      "Epoch [1851/2000], Loss D: 1.2106, Loss G: 1.0351\n",
      "Epoch [1852/2000], Loss D: 1.3965, Loss G: 0.8308\n",
      "Epoch [1853/2000], Loss D: 1.3634, Loss G: 0.9766\n",
      "Epoch [1854/2000], Loss D: 1.3566, Loss G: 1.1365\n",
      "Epoch [1855/2000], Loss D: 1.2749, Loss G: 1.1378\n",
      "Epoch [1856/2000], Loss D: 1.1216, Loss G: 1.2969\n",
      "Epoch [1857/2000], Loss D: 0.9616, Loss G: 1.5684\n",
      "Epoch [1858/2000], Loss D: 1.0031, Loss G: 1.8961\n",
      "Epoch [1859/2000], Loss D: 0.8315, Loss G: 1.6733\n",
      "Epoch [1860/2000], Loss D: 0.6917, Loss G: 1.9834\n",
      "Epoch [1861/2000], Loss D: 0.6491, Loss G: 1.9787\n",
      "Epoch [1862/2000], Loss D: 0.5652, Loss G: 2.0804\n",
      "Epoch [1863/2000], Loss D: 0.5097, Loss G: 2.0088\n",
      "Epoch [1864/2000], Loss D: 0.4711, Loss G: 2.1294\n",
      "Epoch [1865/2000], Loss D: 0.4234, Loss G: 1.9880\n",
      "Epoch [1866/2000], Loss D: 0.4832, Loss G: 1.9046\n",
      "Epoch [1867/2000], Loss D: 0.6172, Loss G: 1.7303\n",
      "Epoch [1868/2000], Loss D: 0.6801, Loss G: 1.5885\n",
      "Epoch [1869/2000], Loss D: 0.6989, Loss G: 1.6270\n",
      "Epoch [1870/2000], Loss D: 0.7071, Loss G: 1.5676\n",
      "Epoch [1871/2000], Loss D: 0.8054, Loss G: 1.4474\n",
      "Epoch [1872/2000], Loss D: 0.8266, Loss G: 1.4813\n",
      "Epoch [1873/2000], Loss D: 0.8577, Loss G: 1.3937\n",
      "Epoch [1874/2000], Loss D: 0.7850, Loss G: 1.6653\n",
      "Epoch [1875/2000], Loss D: 0.7363, Loss G: 2.0647\n",
      "Epoch [1876/2000], Loss D: 0.6412, Loss G: 2.1223\n",
      "Epoch [1877/2000], Loss D: 0.4217, Loss G: 2.6831\n",
      "Epoch [1878/2000], Loss D: 0.7087, Loss G: 2.4623\n",
      "Epoch [1879/2000], Loss D: 0.7106, Loss G: 3.7183\n",
      "Epoch [1880/2000], Loss D: 0.5914, Loss G: 3.0030\n",
      "Epoch [1881/2000], Loss D: 0.5154, Loss G: 1.7790\n",
      "Epoch [1882/2000], Loss D: 0.5052, Loss G: 1.9905\n",
      "Epoch [1883/2000], Loss D: 0.4465, Loss G: 2.1759\n",
      "Epoch [1884/2000], Loss D: 0.4202, Loss G: 2.3690\n",
      "Epoch [1885/2000], Loss D: 0.4264, Loss G: 2.3914\n",
      "Epoch [1886/2000], Loss D: 0.4228, Loss G: 2.1975\n",
      "Epoch [1887/2000], Loss D: 0.4087, Loss G: 2.0913\n",
      "Epoch [1888/2000], Loss D: 0.3938, Loss G: 2.2481\n",
      "Epoch [1889/2000], Loss D: 0.3886, Loss G: 2.2888\n",
      "Epoch [1890/2000], Loss D: 0.3558, Loss G: 2.3155\n",
      "Epoch [1891/2000], Loss D: 0.3604, Loss G: 2.2621\n",
      "Epoch [1892/2000], Loss D: 0.3413, Loss G: 2.3099\n",
      "Epoch [1893/2000], Loss D: 0.3124, Loss G: 2.4317\n",
      "Epoch [1894/2000], Loss D: 0.2940, Loss G: 2.4607\n",
      "Epoch [1895/2000], Loss D: 0.2829, Loss G: 2.4933\n",
      "Epoch [1896/2000], Loss D: 0.3022, Loss G: 2.5751\n",
      "Epoch [1897/2000], Loss D: 0.2800, Loss G: 2.5236\n",
      "Epoch [1898/2000], Loss D: 0.2769, Loss G: 2.5721\n",
      "Epoch [1899/2000], Loss D: 0.2675, Loss G: 2.5776\n",
      "Epoch [1900/2000], Loss D: 0.2806, Loss G: 2.5693\n",
      "Epoch [1901/2000], Loss D: 0.2601, Loss G: 2.7341\n",
      "Epoch [1902/2000], Loss D: 0.2579, Loss G: 2.5703\n",
      "Epoch [1903/2000], Loss D: 0.2723, Loss G: 2.6091\n",
      "Epoch [1904/2000], Loss D: 0.2674, Loss G: 2.7024\n",
      "Epoch [1905/2000], Loss D: 0.2590, Loss G: 2.5453\n",
      "Epoch [1906/2000], Loss D: 0.2572, Loss G: 2.6808\n",
      "Epoch [1907/2000], Loss D: 0.2748, Loss G: 2.5794\n",
      "Epoch [1908/2000], Loss D: 0.2747, Loss G: 2.7671\n",
      "Epoch [1909/2000], Loss D: 0.2652, Loss G: 2.5486\n",
      "Epoch [1910/2000], Loss D: 0.2597, Loss G: 2.5922\n",
      "Epoch [1911/2000], Loss D: 0.2564, Loss G: 2.7289\n",
      "Epoch [1912/2000], Loss D: 0.2382, Loss G: 2.7010\n",
      "Epoch [1913/2000], Loss D: 0.2430, Loss G: 2.7930\n",
      "Epoch [1914/2000], Loss D: 0.2179, Loss G: 2.7770\n",
      "Epoch [1915/2000], Loss D: 0.2114, Loss G: 2.7168\n",
      "Epoch [1916/2000], Loss D: 0.2153, Loss G: 2.8350\n",
      "Epoch [1917/2000], Loss D: 0.2131, Loss G: 2.8025\n",
      "Epoch [1918/2000], Loss D: 0.2131, Loss G: 2.7123\n",
      "Epoch [1919/2000], Loss D: 0.2210, Loss G: 2.7285\n",
      "Epoch [1920/2000], Loss D: 0.2470, Loss G: 2.6471\n",
      "Epoch [1921/2000], Loss D: 0.2678, Loss G: 2.5343\n",
      "Epoch [1922/2000], Loss D: 0.2865, Loss G: 2.5285\n",
      "Epoch [1923/2000], Loss D: 0.2551, Loss G: 2.4780\n",
      "Epoch [1924/2000], Loss D: 0.2824, Loss G: 2.6772\n",
      "Epoch [1925/2000], Loss D: 0.3146, Loss G: 2.8112\n",
      "Epoch [1926/2000], Loss D: 0.3238, Loss G: 2.6699\n",
      "Epoch [1927/2000], Loss D: 0.2694, Loss G: 3.1981\n",
      "Epoch [1928/2000], Loss D: 0.2869, Loss G: 2.8943\n",
      "Epoch [1929/2000], Loss D: 0.2794, Loss G: 3.3908\n",
      "Epoch [1930/2000], Loss D: 0.3898, Loss G: 2.6786\n",
      "Epoch [1931/2000], Loss D: 0.8473, Loss G: 1.5358\n",
      "Epoch [1932/2000], Loss D: 0.5599, Loss G: 4.1692\n",
      "Epoch [1933/2000], Loss D: 0.5909, Loss G: 3.6404\n",
      "Epoch [1934/2000], Loss D: 5.7795, Loss G: 6.2103\n",
      "Epoch [1935/2000], Loss D: 2.2293, Loss G: 1.1854\n",
      "Epoch [1936/2000], Loss D: 1.7116, Loss G: 1.0467\n",
      "Epoch [1937/2000], Loss D: 1.7487, Loss G: 0.6986\n",
      "Epoch [1938/2000], Loss D: 1.0141, Loss G: 1.7277\n",
      "Epoch [1939/2000], Loss D: 1.9363, Loss G: 1.9232\n",
      "Epoch [1940/2000], Loss D: 1.1691, Loss G: 1.1461\n",
      "Epoch [1941/2000], Loss D: 1.0771, Loss G: 1.1666\n",
      "Epoch [1942/2000], Loss D: 0.9429, Loss G: 1.1635\n",
      "Epoch [1943/2000], Loss D: 0.9231, Loss G: 1.2353\n",
      "Epoch [1944/2000], Loss D: 0.9448, Loss G: 1.3094\n",
      "Epoch [1945/2000], Loss D: 0.8577, Loss G: 1.3480\n",
      "Epoch [1946/2000], Loss D: 0.8478, Loss G: 1.3039\n",
      "Epoch [1947/2000], Loss D: 0.8735, Loss G: 1.3712\n",
      "Epoch [1948/2000], Loss D: 0.9436, Loss G: 1.2796\n",
      "Epoch [1949/2000], Loss D: 1.1214, Loss G: 1.1120\n",
      "Epoch [1950/2000], Loss D: 1.1309, Loss G: 1.0267\n",
      "Epoch [1951/2000], Loss D: 1.3940, Loss G: 0.8715\n",
      "Epoch [1952/2000], Loss D: 1.4883, Loss G: 0.8685\n",
      "Epoch [1953/2000], Loss D: 1.4918, Loss G: 0.9219\n",
      "Epoch [1954/2000], Loss D: 1.8270, Loss G: 1.0183\n",
      "Epoch [1955/2000], Loss D: 1.0684, Loss G: 1.1614\n",
      "Epoch [1956/2000], Loss D: 2.7348, Loss G: 1.3198\n",
      "Epoch [1957/2000], Loss D: 2.6942, Loss G: 1.4071\n",
      "Epoch [1958/2000], Loss D: 1.5734, Loss G: 1.2986\n",
      "Epoch [1959/2000], Loss D: 1.3362, Loss G: 1.0952\n",
      "Epoch [1960/2000], Loss D: 1.4897, Loss G: 0.8701\n",
      "Epoch [1961/2000], Loss D: 1.6350, Loss G: 0.7907\n",
      "Epoch [1962/2000], Loss D: 1.7464, Loss G: 0.7153\n",
      "Epoch [1963/2000], Loss D: 1.5961, Loss G: 0.7276\n",
      "Epoch [1964/2000], Loss D: 2.2614, Loss G: 0.6994\n",
      "Epoch [1965/2000], Loss D: 1.5136, Loss G: 1.1257\n",
      "Epoch [1966/2000], Loss D: 2.5183, Loss G: 1.2718\n",
      "Epoch [1967/2000], Loss D: 1.2370, Loss G: 0.8675\n",
      "Epoch [1968/2000], Loss D: 1.1287, Loss G: 0.9441\n",
      "Epoch [1969/2000], Loss D: 1.0582, Loss G: 1.0027\n",
      "Epoch [1970/2000], Loss D: 1.0214, Loss G: 0.9895\n",
      "Epoch [1971/2000], Loss D: 1.1954, Loss G: 0.9325\n",
      "Epoch [1972/2000], Loss D: 1.1039, Loss G: 0.8903\n",
      "Epoch [1973/2000], Loss D: 1.0840, Loss G: 0.9176\n",
      "Epoch [1974/2000], Loss D: 1.0723, Loss G: 0.9315\n",
      "Epoch [1975/2000], Loss D: 1.0764, Loss G: 0.9292\n",
      "Epoch [1976/2000], Loss D: 1.0792, Loss G: 0.9179\n",
      "Epoch [1977/2000], Loss D: 1.1644, Loss G: 0.8701\n",
      "Epoch [1978/2000], Loss D: 1.1753, Loss G: 0.8596\n",
      "Epoch [1979/2000], Loss D: 1.1625, Loss G: 0.8817\n",
      "Epoch [1980/2000], Loss D: 1.1792, Loss G: 0.8629\n",
      "Epoch [1981/2000], Loss D: 1.2348, Loss G: 0.8413\n",
      "Epoch [1982/2000], Loss D: 1.2882, Loss G: 0.8165\n",
      "Epoch [1983/2000], Loss D: 1.3292, Loss G: 0.7987\n",
      "Epoch [1984/2000], Loss D: 1.3609, Loss G: 0.7687\n",
      "Epoch [1985/2000], Loss D: 1.4020, Loss G: 0.7540\n",
      "Epoch [1986/2000], Loss D: 1.3854, Loss G: 0.7613\n",
      "Epoch [1987/2000], Loss D: 1.3566, Loss G: 0.7803\n",
      "Epoch [1988/2000], Loss D: 1.3410, Loss G: 0.7865\n",
      "Epoch [1989/2000], Loss D: 1.3094, Loss G: 0.7928\n",
      "Epoch [1990/2000], Loss D: 1.2859, Loss G: 0.8209\n",
      "Epoch [1991/2000], Loss D: 1.2498, Loss G: 0.8264\n",
      "Epoch [1992/2000], Loss D: 1.2056, Loss G: 0.8486\n",
      "Epoch [1993/2000], Loss D: 1.1680, Loss G: 0.8806\n",
      "Epoch [1994/2000], Loss D: 1.1805, Loss G: 0.8853\n",
      "Epoch [1995/2000], Loss D: 1.1859, Loss G: 0.8624\n",
      "Epoch [1996/2000], Loss D: 1.1726, Loss G: 0.8608\n",
      "Epoch [1997/2000], Loss D: 1.2238, Loss G: 0.8461\n",
      "Epoch [1998/2000], Loss D: 1.3565, Loss G: 0.7721\n",
      "Epoch [1999/2000], Loss D: 1.4112, Loss G: 0.7529\n",
      "Epoch [2000/2000], Loss D: 1.4113, Loss G: 0.7523\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Track losses\n",
    "losses_D = []\n",
    "losses_G = []\n",
    "\n",
    "def train_GAN(generator, discriminator, data, epochs=1000, batch_size=32):\n",
    "    real_label = 1.0\n",
    "    fake_label = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss_D = 0\n",
    "        epoch_loss_G = 0\n",
    "\n",
    "        for i in range(0, len(data) - batch_size, batch_size):\n",
    "            real_data = torch.tensor(data[i:i + batch_size], dtype=torch.float32).to(device)\n",
    "\n",
    "            # Train Discriminator\n",
    "            discriminator.zero_grad()\n",
    "            output_real = discriminator(real_data)\n",
    "            label_real = torch.full((batch_size, 1), real_label, dtype=torch.float32).to(device)\n",
    "            loss_real = criterion(output_real, label_real)\n",
    "\n",
    "            noise = torch.randn(batch_size, seq_length, feature_dim).to(device)\n",
    "            fake_data = generator(noise)\n",
    "            output_fake = discriminator(fake_data.detach())\n",
    "            label_fake = torch.full((batch_size, 1), fake_label, dtype=torch.float32).to(device)\n",
    "            loss_fake = criterion(output_fake, label_fake)\n",
    "\n",
    "            loss_D = loss_real + loss_fake\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "            epoch_loss_D += loss_D.item()\n",
    "\n",
    "            # Train Generator\n",
    "            generator.zero_grad()\n",
    "            output_fake_for_G = discriminator(fake_data)\n",
    "            label_gen = torch.full((batch_size, 1), real_label, dtype=torch.float32).to(device)\n",
    "            loss_G = criterion(output_fake_for_G, label_gen)\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "            epoch_loss_G += loss_G.item()\n",
    "\n",
    "        losses_D.append(epoch_loss_D / (len(data) // batch_size))\n",
    "        losses_G.append(epoch_loss_G / (len(data) // batch_size))\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss D: {losses_D[-1]:.4f}, Loss G: {losses_G[-1]:.4f}\")\n",
    "\n",
    "train_GAN(generator, discriminator, train_sequences, epochs=2000, batch_size=32)\n",
    "# Visualize losses\n",
    "plt.plot(losses_D, label=\"Discriminator Loss\")\n",
    "plt.plot(losses_G, label=\"Generator Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
